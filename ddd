import pandas as pd
import numpy as np
from numpy.random import gamma
from numba import njit, prange


from numba import njit
import numpy as np
from numba import njit
import numpy as np

@njit
def run_simulations_numpy_numba(tri_base, residuals, mask, phi, a2a, nbr_samples=1000):
    n_rows, n_cols = tri_base.shape
    results = []
    sqrt_tri = np.sqrt(np.abs(tri_base))
    mask_np = ~np.isnan(tri_base)

    for i in range(nbr_samples):
        sampled_resid = np.empty_like(tri_base)
        for r in range(n_rows):
            for c in range(n_cols):
                if mask[r+1, c+1]:
                    idx = np.random.randint(0, residuals.shape[0])
                    sampled_resid[r, c] = residuals[idx]
                else:
                    sampled_resid[r, c] = 0.0

        tri_sim = tri_base + sampled_resid * sqrt_tri

        # cumsum axis=1
        ctri_sim = np.empty_like(tri_sim)
        for r in range(n_rows):
            acc = 0.0
            for c in range(n_cols):
                acc += tri_sim[r, c]
                ctri_sim[r, c] = acc

        n_rows, n_cols = ctri_sim.shape
        a2a = []
        for j in range(n_cols - 1):
            weighted_sum = 0.0
            weights_sum = 0.0
            for i in range(n_rows):
                if i + j + 1 < n_cols and ctri_sim[i, j] != 0:
                    df_ij = ctri_sim[i, j + 1] / ctri_sim[i, j]
                    weight = ctri_sim[i, j]
                    weighted_sum += df_ij * weight
                    weights_sum += weight
            factor = weighted_sum / weights_sum if weights_sum != 0 else 1.0
            a2a.append(factor)

        for r in range(1, n_rows):
            for c in range(n_cols - r, n_cols):
                ctri_sim[r, c] = ctri_sim[r, c - 1] * a2a[c - 1]

        tri_sqrd = np.empty_like(ctri_sim)
        for r in range(n_rows):
            tri_sqrd[r, 0] = ctri_sim[r, 0]
            for c in range(1, n_cols):
                tri_sqrd[r, c] = ctri_sim[r, c] - ctri_sim[r, c - 1]

        # gamma sampling
        for r in range(1, n_rows):
            for c in range(n_cols):
                if c < n_cols - r:
                    continue
                m = np.abs(tri_sqrd[r, c])
                if m == 0:
                    continue
                v = m * phi
                shape = m * m / v if v != 0 else 1.0
                scale = v / m if m != 0 else 1.0
                tri_sqrd[r, c] = np.random.gamma(shape, scale)

        # cumsum axis=1 again
        ctri_sqrd2 = np.empty_like(tri_sqrd)
        for r in range(n_rows):
            acc = 0.0
            for c in range(n_cols):
                acc += tri_sqrd[r, c]
                ctri_sqrd2[r, c] = acc
        results.append(np.sum(ctri_sqrd2[:, -1]))

    #    results[i] = float(np.sum(ctri_sqrd2[:, -1]))

    return results


@njit
def stochastic_triangle_forward_numba_batched(data_paid, sigma_j, dev, sd,
                                              sim_total=1000, batch_sim=1000,
                                              ultimate_param_resrisk=0,
                                              main_seed=202260011):
    mm, n_cols_orig = data_paid.shape
    n_dev = len(dev)
    results = np.zeros(sim_total)
    num_batches = sim_total // batch_sim

    for batch in range(num_batches):
        seed = main_seed + batch
        mu_part = np.empty((batch_sim, n_dev))
        sigma_part = np.empty((batch_sim, n_dev))

        for j in range(n_dev):
            np.random.seed(seed + j)
            mu_part[:, j] = np.random.normal(loc=dev[j], scale=sd[j], size=batch_sim)
            df = max(1, mm - j - 1)
            chi_list = np.random.chisquare(df, size=batch_sim)
            for s in range(batch_sim):
                sigma_part[s, j] = (np.floor(chi_list[s]) * sigma_j[j]) / df

        for i in range(batch_sim):
            np.random.seed(seed + i)
            m_i = mu_part[i, :]
            sigma_i = sigma_part[i, :]
            data_paid_copy = np.copy(data_paid).astype(np.float64)
            n_cols_current = data_paid_copy.shape[1]

            if n_cols_current < n_dev + 1:
                extra_cols = (n_dev + 1) - n_cols_current
                extended = np.empty((mm, n_cols_current + extra_cols), dtype=np.float64)
                extended[:, :n_cols_current] = data_paid_copy
                extended[:, n_cols_current:] = 0.0
                data_paid_copy = extended
                n_cols_current = data_paid_copy.shape[1]

            for j in range(n_dev):
                max_ind_row = max(1, mm - j)
                for r in range(max_ind_row - 1, mm):
                    # OBSŁUGA ZER: jeśli wartość jest zerem, ustaw pozostałe kolumny w tym wierszu na zero
                    if data_paid_copy[r, j] <= 0:
                        # Ustaw wszystkie kolejne kolumny w tym wierszu na zero
                        for next_col in range(j + 1, n_cols_current):
                            data_paid_copy[r, next_col] = 0.0
                        continue
                    
                    var_ij = sigma_i[j] / data_paid_copy[r, j]
                    m_sq = m_i[j] * m_i[j]
                    denom = np.sqrt(m_sq + var_ij)
                    
                    lmean = np.log(m_sq / denom)
                    lstdev = np.sqrt(np.log(1 + (var_ij / m_sq)))
                    
                    cl_ij = np.random.lognormal(lmean, lstdev)
                    data_paid_copy[r, j + 1] = data_paid_copy[r, j] * cl_ij

            u_i = data_paid_copy[:, n_cols_current - 1]
            results[batch * batch_sim + i] = np.sum(u_i) - ultimate_param_resrisk

    return results

import numpy as np
from numba import njit

@njit
def divide(x, y):
    result = np.zeros_like(x)
    for i in range(len(x)):
        result[i] = 0 if y[i] == 0 else x[i] / y[i]
    return result

from numba import njit
import numpy as np

@njit
def divide(num_vec, den_vec):
    out = np.zeros_like(num_vec)
    for i in range(num_vec.shape[0]):
        d = den_vec[i]
        out[i] = 0.0 if d == 0.0 else num_vec[i] / d
    return out

from numba import njit
import numpy as np

@njit
def divide(num_vec, den_vec):
    out = np.zeros_like(num_vec)
    for i in range(num_vec.shape[0]):
        d = den_vec[i]
        out[i] = 0.0 if d == 0.0 else num_vec[i] / d
    return out

from numba import njit
import numpy as np

@njit
def divide(num_vec, den_vec):
    out = np.zeros_like(num_vec)
    for i in range(num_vec.shape[0]):
        d = den_vec[i]
        out[i] = 0.0 if d == 0.0 else num_vec[i] / d
    return out


from numba import njit
import numpy as np
@njit
def divide(num_vec, den_vec):
    out = np.zeros_like(num_vec)
    for i in range(num_vec.shape[0]):
        d = den_vec[i]
        out[i] = 0.0 if d == 0.0 else num_vec[i] / d
    return out

from numba import njit
import numpy as np

@njit
def divide(num_vec, den_vec):
    out = np.zeros_like(num_vec)
    for i in range(num_vec.shape[0]):
        d = den_vec[i]
        out[i] = 0.0 if d == 0.0 else num_vec[i] / d
    return out

from numba import njit
import numpy as np

@njit
def divide(num_vec, den_vec):
    out = np.zeros_like(num_vec)
    for i in range(num_vec.shape[0]):
        d = den_vec[i]
        out[i] = 0.0 if d == 0.0 else num_vec[i] / d
    return out


@njit
def run_bootstrap_monte_carlo(triangle, weight, number_of_simulations=1000, is_sigma_reestimated=True, sigma_tail=1.65):
    triangle = np.nan_to_num(triangle)
    weight = np.nan_to_num(weight)
    a = triangle.shape[0]

    indiv_factors = np.zeros((a-1, a-1))
    for k in range(a-1):
        indiv_factors[:, k] = divide(triangle[:a-1, k+1], triangle[:a-1, k])

    indiv_factors_weighted = indiv_factors * weight[:a-1, :a-1]

    ldf = np.zeros(a-1)
    for k in range(a-1):
        num = 0.0
        den = 0.0
        for i in range(a-1):
            num += triangle[i, k] * indiv_factors_weighted[i, k]
            den += triangle[i, k] * weight[i, k]
        ldf[k] = 1.0 if den == 0 else num / den

    sigma = np.zeros(a-1)
    for k in range(a-1):
        num = 0.0
        den = 0.0
        for i in range(a-1):
            diff = indiv_factors_weighted[i, k] - ldf[k]
            w = weight[i, k]
            num += triangle[i, k] * w * diff * diff
            den += w
        sigma[k] = 0.0 if den <= 1 else np.sqrt(num / (den - 1))

    if a >= 4:
        sigma[a-2] = np.sqrt(min((sigma[a-3]**2 / sigma[a-4])**2, min(sigma[a-3]**2, sigma[a-4]**2)))

    for k in range(a-1):
        wsum = 0.0
        for i in range(a-1):
            wsum += weight[i, k]
        if wsum == 1.0:
            sigma[k] = sigma[max(0, k-1)]
        elif wsum == 0.0:
            sigma[k] = sigma_tail

    ln_mu_bootstrap = np.zeros((a, a-1))
    ln_sd_bootstrap = np.zeros((a, a-1))
    for k in range(a):
        for i in range(a-1):
            x = triangle[k, i]
            if x == 0:
                ln_mu_bootstrap[k, i] = -1e10  # zamiast -np.inf
                ln_sd_bootstrap[k, i] = 0.0
            else:
                mean_val = ldf[i] * x
                variance_ratio = (x * sigma[i]**2) / (mean_val**2)
                ln_mu_bootstrap[k, i] = np.log(mean_val) - 0.5 * np.log(variance_ratio + 1.0)
                ln_sd_bootstrap[k, i] = np.sqrt(np.log(variance_ratio + 1.0))

    ult = np.zeros(number_of_simulations)

    for n in range(number_of_simulations):
        triangle_boot = np.zeros((a, a))
        for i in range(a):
            triangle_boot[i, 0] = triangle[i, 0]

        for k in range(a):
            for i in range(1, a):
                if triangle_boot[k, i-1] != 0:
                    mu = ln_mu_bootstrap[k, i-1]
                    sigma_ln = ln_sd_bootstrap[k, i-1]
                    triangle_boot[k, i] = np.random.lognormal(mu, sigma_ln)

        indiv_f_boot = np.zeros((a-1, a-1))
        for k in range(a-1):
            indiv_f_boot[:, k] = divide(triangle_boot[:a-1, k+1], triangle[:a-1, k])
        indiv_f_boot_weighted = indiv_f_boot * weight[:a-1, :a-1]

        ldf_boot = np.zeros(a-1)
        for k in range(a-1):
            num = 0.0
            den = 0.0
            for i in range(a-1):
                num += triangle[i, k] * indiv_f_boot_weighted[i, k]
                den += triangle[i, k] * weight[i, k]
            ldf_boot[k] = 1.0 if den == 0 else num / den

        sigma_boot = sigma.copy()
        if is_sigma_reestimated:
            for k in range(a-1):
                num = 0.0
                den = 0.0
                for i in range(a-1):
                    diff = indiv_f_boot_weighted[i, k] - ldf_boot[k]
                    w = weight[i, k]
                    num += triangle[i, k] * w * diff * diff
                    den += w
                sigma_boot[k] = 0.0 if den <= 1 else np.sqrt(num / (den - 1))
                if k == a-2 and a >= 3:
                    sigma_boot[k] = np.sqrt(min((sigma_boot[k-1]**2 / sigma_boot[k-2])**2,
                                                min(sigma_boot[k-1]**2, sigma_boot[k-2]**2)))
                wsum = 0.0
                for i in range(a-1):
                    wsum += weight[i, k]
                if wsum == 1:
                    sigma_boot[k] = sigma_boot[max(0, k-1)]
                elif wsum == 0:
                    sigma_boot[k] = sigma_tail

        triangle_simu = np.zeros((a, a))
        for i in range(a):
            for j in range(a):
                triangle_simu[i, j] = triangle[i, j]

        for k in range(a):
            for i in range(1, a):
                if k + i >= a and triangle_simu[k, i-1] != 0:
                    prev = triangle_simu[k, i-1]
                    mu = np.log(ldf_boot[i-1] * prev) - 0.5 * np.log((prev * sigma_boot[i-1]**2) / (ldf_boot[i-1]**2 * prev**2) + 1)
                    sigma_ln = np.sqrt(np.log((prev * sigma_boot[i-1]**2) / (ldf_boot[i-1]**2 * prev**2) + 1))
                    triangle_simu[k, i] = np.random.lognormal(mu, sigma_ln)

        ult[n] = np.sum(triangle_simu[:, a-1])

    return ult




class TriangleCalculator:
    # === PANDAS SECTION ===

    @staticmethod
    def to_cum(tri: pd.DataFrame) -> pd.DataFrame:
        return tri.cumsum(axis=1)

    @staticmethod
    def to_incr(tri: pd.DataFrame) -> pd.DataFrame:
        tri_incr = tri.diff(axis=1)
        tri_incr.iloc[:, 0] = tri.iloc[:, 0]
        return tri_incr

    @staticmethod
    def get_a2a_factors(tri: pd.DataFrame) -> pd.Series:
        all_devps = tri.columns.tolist()
        min_origin, max_origin = tri.index.min(), tri.index.max()
        dps0, dps1 = all_devps[:-1], all_devps[1:]
        a2a_headers = [f"{ii}-{jj}" for ii, jj in zip(dps0, dps1)]
        a2a = []

        for dp1, dp0 in zip(dps1[::-1], dps0[::-1]):
            vals1 = tri.loc[min_origin:(max_origin - dp0), dp1].sum()
            vals0 = tri.loc[min_origin:(max_origin - dp0), dp0].sum()
            # Zabezpieczenie przed dzieleniem przez zero
            if vals0 == 0 or pd.isna(vals0) or pd.isna(vals1):
                a2a.append(1.0)
            else:
                a2a.append((vals1 / vals0).item())

        return pd.Series(data=a2a[::-1], index=a2a_headers)

    @staticmethod
    def get_a2u_factors(a2a: pd.Series) -> pd.Series:
        return pd.Series(np.cumprod(a2a[::-1])[::-1], index=a2a.index, name="A2U")

    @staticmethod
    def fit_triangle_from_latest(ctri0: pd.DataFrame, a2a: pd.Series) -> pd.DataFrame:
        nbr_devps = ctri0.shape[1]
        ctri = pd.DataFrame(columns=ctri0.columns, index=ctri0.index, dtype=float)

        for idx, origin in enumerate(ctri0.index):
            latest_devp = nbr_devps - idx
            if latest_devp <= 0 or latest_devp > nbr_devps:
                continue
            ctri.at[origin, latest_devp] = ctri0.at[origin, latest_devp]
            for devp in range(latest_devp - 1, 0, -1):
                ctri.at[origin, devp] = float(ctri.at[origin, devp + 1]) / float(a2a.iloc[devp - 1])

        return ctri

    @staticmethod
    def full_ci_calculation(df: pd.DataFrame) -> tuple[pd.DataFrame, float]:
        a2a = TriangleCalculator.get_a2a_factors(df)
        ctri = TriangleCalculator.fit_triangle_from_latest(df, a2a)
        tri0 = TriangleCalculator.to_incr(df)
        tri = TriangleCalculator.to_incr(ctri)

        tri_values = tri.to_numpy()
        tri0_values = tri0.to_numpy()

        denom = np.sqrt(np.abs(tri_values))
        numer = tri0_values - tri_values

        r_us = np.where(denom != 0, numer / denom, 0.0)

        r_us_df = pd.DataFrame(r_us, index=tri.index, columns=tri.columns)

        n_obs = np.isfinite(tri0_values).sum()
        n_rows, n_cols = tri0.shape
        p = n_rows + n_cols - 1
        DF = n_obs - p

        rss = (r_us ** 2).sum()
        phi = rss / DF

        r_adj = np.sqrt(n_obs / DF) * r_us_df

        return r_adj, phi

    @staticmethod
    def square_tri(tri: pd.DataFrame, a2a: pd.Series) -> pd.DataFrame:
        nbr_devps = tri.shape[1]
        for r_idx in range(1, nbr_devps):
            for c_idx in range(nbr_devps - r_idx, nbr_devps):
                tri.iat[r_idx, c_idx] = tri.iat[r_idx, c_idx - 1] * a2a.iat[c_idx - 1]
        return tri

    @staticmethod
    def sample_with_process_variance(ctri_ii_sqrd: pd.DataFrame, phi: float, rng=None) -> pd.DataFrame:
        if rng is None:
            rng = np.random.default_rng(seed=516)
        nbr_devps = ctri_ii_sqrd.shape[0]
        tri_ii_sqrd = ctri_ii_sqrd.copy()
        for r_idx in range(1, nbr_devps):
            for c_idx in range(nbr_devps - r_idx, nbr_devps):
                m = np.abs(tri_ii_sqrd.iat[r_idx, c_idx])
                v = m * phi
                shape = m ** 2 / v if v != 0 else 1.0
                scale = v / m if m != 0 else 1.0
                tri_ii_sqrd.iat[r_idx, c_idx] = rng.gamma(shape=shape, scale=scale)
        return tri_ii_sqrd

    # === NUMPY SECTION ===

    @staticmethod
    def to_cum_np(tri: np.ndarray) -> np.ndarray:
        return np.cumsum(tri, axis=1)

    @staticmethod
    def to_incr_np(tri: np.ndarray) -> np.ndarray:
        result = np.diff(tri, axis=1, prepend=0)
        result[:, 0] = tri[:, 0]
        return result

    @staticmethod
    def get_a2a_factors_np(tri: np.ndarray, mask: np.ndarray) -> np.ndarray:
        n_rows, n_cols = tri.shape
        a2a = []
        for j in range(n_cols - 1):
            vals0 = []
            vals1 = []
            for i in range(n_rows):
                if i + j + 1 < n_cols and mask[i, j] and mask[i, j + 1]:
                    vals0.append(tri[i, j])
                    vals1.append(tri[i, j + 1])
            num = np.nansum(vals1)
            denom = np.nansum(vals0)
            a2a.append(num / denom if denom != 0 else 1.0)
        return np.array(a2a)

    @staticmethod
    def square_tri_np(tri: np.ndarray, a2a: np.ndarray) -> np.ndarray:
        tri = tri.copy()
        n_rows, n_cols = tri.shape
        for i in range(1, n_rows):
            for j in range(n_cols - i, n_cols):
                tri[i, j] = tri[i, j - 1] * a2a[j - 1]
        return tri

    @staticmethod
    def to_mask_np(tri: np.ndarray) -> np.ndarray:
        return ~np.isnan(tri)

    @staticmethod
    def full_ci_calculation_np(df: np.ndarray, mask: np.ndarray, mask_reszty: np.ndarray) -> tuple[np.ndarray, float]:
        ctri = TriangleCalculator.fit_triangle_from_latest_np(df, mask)
        tri0 = TriangleCalculator.to_incr_np(df)
        tri = TriangleCalculator.to_incr_np(ctri)

        denom = np.sqrt(np.abs(tri))
        numer = tri0 - tri

        # Zabezpieczenie przed dzieleniem przez zero i nieprawidłowymi wartościami
        with np.errstate(divide='ignore', invalid='ignore'):
            r_us = np.where((denom != 0) & np.isfinite(denom) & np.isfinite(numer), 
                           numer / denom, 0.0)

        # Poprawiona maska: tylko tam gdzie są rzeczywiste dane (nie NaN i nie tylko zera)
        valid_data_mask = (~np.isnan(tri0)) & (~np.isnan(tri)) & (np.abs(tri) > 1e-10)
        
        # Konwersja mask_reszty do bool aby uniknąć błędów typów
        mask_reszty_bool = np.array(mask_reszty, dtype=bool)
        actual_mask = mask_reszty_bool & valid_data_mask
        
        n = np.count_nonzero(actual_mask == 1.0)
        p = df.shape[0] + df.shape[1] - 1
        DF = n - p
        if DF < 1:
            print(f"DF < 1 ({DF}), ustawiam DF=1")
            DF = 1

        # Zmiana: 
        # - Jeśli actual_mask == 1 (rzeczywiste dane), użyj reszty
        # - W pozostałych przypadkach ustaw na 0 (zamiast NaN)
        masked_r_us = np.where(actual_mask == 1.0, r_us, 0.0)
        
        phi = np.nansum(masked_r_us ** 2) / DF
        r_adj = np.sqrt(n / DF) * masked_r_us

        return r_adj, phi


    @staticmethod
    def fit_triangle_from_latest_np(ctri0: np.ndarray, mask: np.ndarray) -> np.ndarray:
        n_rows, n_cols = ctri0.shape
        ctri = np.full((n_rows, n_cols), np.nan)
        a2a = TriangleCalculator.get_a2a_factors_np(ctri0, mask)
        for i in range(n_rows):
            latest = n_cols - i - 1
            if 0 <= latest < n_cols:
                ctri[i, latest] = ctri0[i, latest]
                for j in range(latest - 1, -1, -1):
                    ctri[i, j] = ctri[i, j + 1] / a2a[j]
        return ctri

    @staticmethod
    def run_simulations_numpy(tri_base: np.ndarray, residuals: np.ndarray, mask: np.ndarray, phi: float, a2a: np.ndarray, nbr_samples=1000, seed=516) -> np.ndarray:
       
        rng = np.random.default_rng(seed)
        results = np.zeros(nbr_samples)
        sqrt_tri = np.sqrt(np.abs(tri_base))
        for i in range(nbr_samples):
            sampled_resid = rng.choice(residuals, size=mask.shape, replace=True)
            tri_sim = tri_base + sampled_resid * sqrt_tri
            ctri_sim = TriangleCalculator.to_cum_np(tri_sim)
            
            a2a_sim = TriangleCalculator.get_a2a_factors_np(ctri_sim, TriangleCalculator.to_mask_np(ctri_sim))
            ctri_sqrd = TriangleCalculator.square_tri_np(ctri_sim, a2a_sim)
            tri_sqrd = TriangleCalculator.to_incr_np(ctri_sqrd)
            for r in range(1, tri_sqrd.shape[0]):
                for c in range(tri_sqrd.shape[1]):
                    if c < tri_sqrd.shape[1] - r:
                        continue
                    m = np.abs(tri_sqrd[r, c])
                    if m == 0 or np.isnan(m):
                        continue
                    v = m * phi
                    shape = m ** 2 / v if v != 0 else 1.0
                    scale = v / m if m != 0 else 1.0
                    tri_sqrd[r, c] = rng.gamma(shape=shape, scale=scale)
            ctri_sqrd2 = TriangleCalculator.to_cum_np(tri_sqrd)
            results[i] = np.nansum(ctri_sqrd2[:, -1])
        return results

    def get_latest(tri: pd.DataFrame) -> pd.Series:

        nbr_devps = tri.shape[1]
        latest = [tri.iat[ii, nbr_devps - ii - 1].item() for ii in range(nbr_devps)]
        return pd.Series(data=latest, index=tri.index, name="latest")

    @staticmethod
    def run_simulations_numpy_nb(tri_base, residuals, mask, phi, a2a, nbr_samples=1000, seed=516):
        np.random.seed(seed)  # ustal seed ręcznie
        return run_simulations_numpy_numba(tri_base, residuals, mask, phi, a2a, nbr_samples)

    @staticmethod
    def run_batched_simulation(data_paid, sigma_j, dev, sd,
                               sim_total=1000, batch_sim=1000,
                               ultimate_param_resrisk=0,
                               main_seed=202260011):
        return stochastic_triangle_forward_numba_batched(
            data_paid, sigma_j, dev, sd,
            sim_total, batch_sim,
            ultimate_param_resrisk,
            main_seed
        )
    
    @staticmethod
    def run_bootstrap_monte_carlo_init(triangle, weight, number_of_simulations=1000, is_sigma_reestimated=True, sigma_tail=1.65):
        return run_bootstrap_monte_carlo(triangle, weight, number_of_simulations, is_sigma_reestimated, sigma_tail)

    
    @staticmethod
    def elementwise_division(data_dict):
        # Konwersja do macierzy
        columns = data_dict.keys()
        data_matrix = np.array([
            [val for val in data_dict[col]]
            for col in columns
        ]).T  # shape: (n_rows, n_cols)

        n_rows, n_cols = data_matrix.shape
        result = [[None for _ in range(n_cols - 1)] for _ in range(n_rows)]

        for i in range(n_rows):
            for j in range(1, n_cols):
                prev = data_matrix[i][j - 1]
                curr = data_matrix[i][j]
                if prev is None or curr is None:
                    result[i][j - 1] = None
                elif prev == 0:
                    result[i][j - 1] = 1
                else:
                    result[i][j - 1] = curr / prev

        return result  # shape: (n_rows, n_cols - 1)
   
    @staticmethod
    def Dev_prem(data_paid, w):
        nn = data_paid.shape[1]
        Dev_j = []
        for j in range(nn - 1):
            mianownik = np.sum([data_paid.iloc[i, j] * w.iloc[i, j] for i in range(nn-j-1)])
            licznik = np.sum([data_paid.iloc[i, j+1] * w.iloc[i, j] for i in range(nn-j-1)])
            if(mianownik==0):
                Dev_j.append(1)
            else:
                Dev_j.append(licznik / mianownik)
        return (Dev_j)
    
    @staticmethod
    def calculate_sigma(p_ij: pd.DataFrame, l_ij: pd.DataFrame, w_ij: pd.DataFrame, dev_j: list[float]) -> list[float]:
        max_col = l_ij.shape[1]
        sigmas = []
        sd = []

        for j in range(0, max_col):  # zaczynamy od j=1, bo potrzebujemy j-1
            numerator = 0.0
            denominator = 0.0
            denominator_sd = 0.0

            for i in range(len(l_ij)):
                try:
                    w = w_ij.iloc[i, j]
                    p = p_ij.iloc[i, j]
                    l = l_ij.iloc[i, j]
                    dev = dev_j[j]

                    if not np.isnan(w) and not np.isnan(p) and not np.isnan(l):
                        numerator += w * p * (l - dev) ** 2
                        denominator += w
                        denominator_sd+=w * p 
                except IndexError:
                    continue
            if denominator > 1:
                sigma = np.sqrt(numerator / (denominator-1))
                sd.append(sigma/np.sqrt(denominator_sd))
            elif j ==(max_col-1) and sigmas[j - 2]!=0 and denominator_sd!=0:
                sigma = min(sigmas[j - 1]**4/sigmas[j - 2]**2, min(sigmas[j - 2]**2, sigmas[j - 1]**2) )
                sd.append(sigma/np.sqrt(denominator_sd))
            else:
                sigma = 0
                sd.append(0)
            sigmas.append(sigma)

        return [sigmas,sd]




###################


class MatrixRequest(BaseModel):
    user_id: str
    paid_data: List[List[Union[str, int, float, None]]]
    paid_weights: List[List[int]]
    cl_data: List[List[Union[str, int, float, None]]]
    cl_weights: List[List[int]]
    triangle_raw: List[List[Union[str, int, float, None]]]
    cl_weights_raw: List[List[int]]
    wagi_mult: Optional[List[List[int]]] = None
    quantiles: Optional[List[float]] = None
    nbr_samples: Optional[int] = 1000

class QuantileRequest(BaseModel):
    user_id: str
    request_id: str
    quantiles: List[float]



class UserSession:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.simulations: Dict[str, Dict] = {}

    def save_simulation(self, request_id: str, sim, diff, latest, quantiles_result=None):
        self.simulations[request_id] = {
            "sim": sim,
            "diff": diff,
            "latest": latest,
            "quantiles": quantiles_result
        }

    def get_simulation(self, request_id: str):
        return self.simulations.get(request_id)


class SessionManager:
    def __init__(self):
        self.sessions: Dict[str, UserSession] = {}

    def get_session(self, user_id: str) -> UserSession:
        if user_id not in self.sessions:
            self.sessions[user_id] = UserSession(user_id)
        return self.sessions[user_id]


SESSIONS = SessionManager()





@app.get("/")
async def root():
    return {"message": "Hello World"}

@app.post("/upload")
async def create_upload_files(file: UploadFile):
    print(file.filename)
    content = await file.read()
    wb = load_workbook(filename=BytesIO(content))
    ws = wb.active
    if ws:
        for row in ws.iter_rows(values_only=True):
            for cell in row:
                if cell:
                    print(cell, end=" ")
            print("")
    return {"filename": file.filename, "size": len(content)}

@app.post("/calc/cl")
async def calc_cl(
    data: List[List[Union[str, int, float, None]]],
    selected: List[List[int]],
):
    print("selected")
    print(selected)
    df = pd.DataFrame(data).iloc[1:, 1:]
    df = df.apply(pd.to_numeric, errors="coerce")
    tri = TriangleCalculator.full_ci_calculation(df)[0]
    print("tri")
    print(pd.DataFrame(tri))
    safe_tri = tri.replace([np.inf, -np.inf], np.nan).astype(object).where(pd.notnull(tri), None)

    matrix = [[tri.columns.name or "AY"] + list(tri.columns)]
    for idx in tri.index:
        values = list(safe_tri.loc[idx])
        while values and values[-1] is None:
            values.pop()
        row = [idx] + values
        matrix.append(row)
    print("matrix")
    print(pd.DataFrame(matrix))
    return {"data": matrix}


@app.post("/calc/full")
async def calc_full(payload: MatrixRequest):
    print("df_triangle_raw")

    start1 = time.time()
    start2 = time.time()

    user_session = SESSIONS.get_session(payload.user_id)

    df_triangle_raw = (
        pd.DataFrame(payload.triangle_raw)
        .iloc[1:, 1:]
        .apply(pd.to_numeric, errors="coerce")
    )
    df_cl_weights_raw = pd.DataFrame(payload.paid_weights).astype(float)
    wagi_z_trojkata = np.array(df_cl_weights_raw.values, dtype=float)

    wagi_z_reszt = pd.DataFrame(payload.cl_weights).astype(float)
    df_np = np.array(df_triangle_raw.values, dtype=float)
    df_bool = wagi_z_reszt.copy()
    mask_reszty = df_bool.to_numpy(dtype=object)

    print(mask_reszty)
    combined_mask = (~np.isnan(df_np))
    mask_np = ~np.isnan(df_np)
    
    tri0_np = TriangleCalculator.to_incr_np(df_np)
    ctri0_np = TriangleCalculator.to_cum_np(tri0_np)
    a2a_np = TriangleCalculator.get_a2a_factors_np(ctri0_np, mask_np)
    ctri_np = TriangleCalculator.fit_triangle_from_latest_np(df_np, mask_np)
    tri_np = TriangleCalculator.to_incr_np(ctri_np)
    r_adj_np, phi_np = TriangleCalculator.full_ci_calculation_np(df_np,mask_np, mask_reszty)
    residuals = r_adj_np[~np.isnan(r_adj_np)].flatten()

    sim_results_np = TriangleCalculator.run_simulations_numpy_nb(
        tri_np, residuals, wagi_z_trojkata, phi_np, a2a_np, nbr_samples=payload.nbr_samples
    )

    latest = np.sum(TriangleCalculator.get_latest(df_triangle_raw))
    sim_diff_np = sim_results_np - latest

    print(f"Czas wykonania symulacje i ibnr: {time.time() - start2:.2f} sekund")

    request_id = str(uuid.uuid4())

    user_session.save_simulation(
        request_id=request_id,
        sim=sim_results_np,
        diff=sim_diff_np,
        latest=latest
    )

    counts, bins = np.histogram(sim_results_np, bins=50)

    print(f"Czas wykonania calosc: {time.time() - start2:.2f} sekund")

    return {
        "message": "OK",
        "request_id": request_id,
        "triangle_shape": df_triangle_raw.shape,
        "histogram": {
            "bins": bins.tolist(),
            "counts": counts.tolist()
        }
    }


@app.post("/calc/quantiles")
async def calc_quantiles(payload: QuantileRequest):
    user_session = SESSIONS.get_session(payload.user_id)
    cached = user_session.get_simulation(payload.request_id)

    if cached is None:
        raise HTTPException(status_code=403, detail="Nie znaleziono danych symulacji")

    sim_results_np = cached["sim"]
    sim_diff_np = cached["diff"]

    quantiles = payload.quantiles
    values_sim = np.quantile(sim_results_np, quantiles)
    values_diff = np.quantile(sim_diff_np, quantiles)

    quantile_result = {
        str(round(q, 4)): {
            "value": float(round(v1, 2)) if np.isfinite(v1) else None,
            "value_minus_latest": float(round(v2, 2)) if np.isfinite(v2) else None
        }
        for q, v1, v2 in zip(quantiles, values_sim, values_diff)
    }

    stats = {
        "mean": {
            "value": float(np.mean(sim_results_np)),
            "value_minus_latest": float(np.mean(sim_diff_np)),
        },
        "variance": {
            "value": float(np.var(sim_results_np)),
            "value_minus_latest": float(np.var(sim_diff_np)),
        },
        "std_dev": {
            "value": float(np.std(sim_results_np)),
            "value_minus_latest": float(np.std(sim_diff_np)),
        },
        "min": {
            "value": float(np.min(sim_results_np)),
            "value_minus_latest": float(np.min(sim_diff_np)),
        },
        "max": {
            "value": float(np.max(sim_results_np)),
            "value_minus_latest": float(np.max(sim_diff_np)),
        },
    }

    return {
        "quantiles": quantile_result,
        "stats": stats
    }

@app.websocket("/ws/progress")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    for i in range(1, 11):
        await websocket.send_json({"progress": i})
        if i < 10:
            await asyncio.sleep(1)
    await websocket.close()

class PercentileRequest(BaseModel):
    user_id: str
    request_id: str
    value: float
    source: str  # 'sim' lub 'diff'

@app.post("/calc/percentile")
async def calc_percentile(payload: PercentileRequest):
    user_session = SESSIONS.get_session(payload.user_id)
    cached = user_session.get_simulation(payload.request_id)

    if cached is None:
        raise HTTPException(status_code=404, detail="Nie znaleziono danych symulacji")

    value = payload.value
    source = payload.source

    def compute_percentile(data, val):
        sorted_data = np.sort(data)
        percentile = np.searchsorted(sorted_data, val, side='right') / len(sorted_data)
        return float(round(percentile, 6))

    if source == 'sim':
        percentile = compute_percentile(cached["sim"], value)
    elif source == 'diff':
        percentile = compute_percentile(cached["diff"], value)
    else:
        raise HTTPException(status_code=400, detail="Nieprawidłowe źródło: musi być 'sim' lub 'diff'")

    return {
        "source": source,
        "percentile": percentile
    }

@app.post("/calc/mult_stoch")
async def calc_mult_stoch(payload: MatrixRequest):
    raw = payload.paid_data

    # odetnij: 1) wiersz nagłówków, 2) pierwszą kolumnę (etykiety wierszy)
    data_rows = [row[1:] for row in raw[1:]]  # [1:] wiersze, [1:] kolumny

    # zbuduj słownik kolumn w kolejności wejścia (po odcięciu 1. kolumny)
    num_cols = len(data_rows[0]) if data_rows else 0
    data = {col_idx: [] for col_idx in range(num_cols)}

    for row in data_rows:
        for col_idx, value in enumerate(row):
            try:
                num_value = float(value)
            except (ValueError, TypeError):
                num_value = None
            data[col_idx].append(num_value)

    # obliczenia
    train_devide = TriangleCalculator.elementwise_division(data)

    # podgląd
    print(pd.DataFrame(data).to_string())
    print("train_devide")
    print(pd.DataFrame(train_devide).to_string())

    train_devide_serializable = np.array(train_devide).tolist()
    return {"train_devide": train_devide_serializable}



class WspolczynnikiMultRequest(BaseModel):
    user_id: str
    wagi_mult: List[List[int]]
    paid_data: List[List[Union[str, int, float, None]]]


import math

def try_parse_float(value):
    try:
        f = float(value)
        if not math.isfinite(f):
            return None
        return f
    except (ValueError, TypeError):
        return None

@app.post("/calc/wspolczynniki_mult")
async def calc_wspolczynniki_mult(payload: WspolczynnikiMultRequest):
    import numpy as np
    import pandas as pd

    paid_data = payload.paid_data
    weights = payload.wagi_mult
    print(pd.DataFrame(weights).to_string())
    print(pd.DataFrame(paid_data).to_string())

    # --- przetwarzanie danych tak samo jak w /calc/paid/cl ---
    # UWAGA: paid_data zawiera nagłówek + pierwszą kolumnę z latami
    actual_data = paid_data[1:]  # pomiń pierwszy wiersz (nagłówek)
    data = {}
    headers = np.arange(len(actual_data[0]) - 1)  # -1 bo pomijamy pierwszą kolumnę
    
    for i, col in enumerate(headers):
        data[col] = []
        for row in actual_data:
            value = row[i + 1]  # +1 bo pomijamy pierwszą kolumnę (lata)
            try:
                num_value = float(value)
            except (ValueError, TypeError):
                num_value = None
            data[col].append(num_value)

    # --- obliczenia ---
    l_ij = pd.DataFrame(TriangleCalculator.elementwise_division(data))
    print(pd.DataFrame(l_ij).to_string())
    p_ij = pd.DataFrame(data)
    w_ij = pd.DataFrame(weights)

    dev_j = TriangleCalculator.Dev_prem(p_ij, w_ij)
    sigmas = TriangleCalculator.calculate_sigma(p_ij, l_ij, w_ij, dev_j)

    print(dev_j)
    print("----")

    # --- JSON-safe (NaN/Inf -> None) ---
    def to_jsonable(x):
        arr = np.asarray(x, dtype=float)
        if arr.ndim == 0:
            return float(arr) if np.isfinite(arr) else None
        out = arr.astype(object)
        out[~np.isfinite(arr)] = None
        return out.tolist()

    return {
        "dev":   to_jsonable(dev_j),
        "sd":    to_jsonable(sigmas[0]),
        "sigma": to_jsonable(sigmas[1]),
    }


class WspolczynnikiMultiplikatywnaStochastycznaRequest(BaseModel):
    user_id: str
    dev: List[float]
    sd: List[float]
    sigma: List[float]
    triangle: List[List[Union[str, int, float, None]]]
    sim_total: Optional[int] = 1000
    batch_sim: Optional[int] = 1000
    main_seed: Optional[int] = 202260011
    ultimate_param_resrisk: Optional[int] = 0

@app.post("/calc/obliczenia_stoch_multiplikatywna")
async def obliczenia_stoch_multiplikatywna(payload: WspolczynnikiMultiplikatywnaStochastycznaRequest):
    print("=== DEBUG /calc/obliczenia_stoch_multiplikatywna ===")
    print("payload.triangle shape:", len(payload.triangle), "x", len(payload.triangle[0]) if payload.triangle else 0)
    
    # Przetwarzanie danych - POMIJAMY nagłówek i pierwszą kolumnę z etykietami
    triangle_data = payload.triangle[1:]  # pomijamy pierwszy wiersz (nagłówek)
    
    data = {}
    headers = np.arange(len(triangle_data[0]) - 1)  # -1 bo pomijamy pierwszą kolumnę
    print("headers:", headers)
    
    for i, col in enumerate(headers):
        data[col] = []
        for row in triangle_data:
            value = row[i + 1]  # +1 bo pomijamy pierwszą kolumnę (etykiety)
            try:
                num_value = float(value)
            except (ValueError, TypeError):
                num_value = None
            data[col].append(num_value)
    
    print("data keys:", list(data.keys()))
    print("data shape:", {k: len(v) for k, v in data.items()})
    
    df_np = np.array(list(data.values()), dtype=float).T
    print("df_np shape:", df_np.shape)
    print("df_np:")
    print(pd.DataFrame(df_np).to_string())
    
    print("payload.sd")
    print(payload.sd)
    print("payload.dev")
    print( payload.dev)
    print("payload.sigma")
    print( payload.sigma)
    
    print("Calling run_batched_simulation...")
    results_cale = TriangleCalculator.run_batched_simulation(df_np, payload.sd, payload.dev, payload.sigma,
                                                             sim_total=payload.sim_total,batch_sim=payload.batch_sim,
                                                             ultimate_param_resrisk=payload.ultimate_param_resrisk,
                                                             main_seed=payload.main_seed)
    
    print("results_cale type:", type(results_cale))
    print("results_cale shape:", results_cale.shape if hasattr(results_cale, 'shape') else 'no shape')
    print("results_cale stats:")
    print(f"  min: {np.min(results_cale)}")
    print(f"  max: {np.max(results_cale)}")
    print(f"  mean: {np.mean(results_cale)}")
    print(f"  nan count: {np.sum(np.isnan(results_cale))}")
    print("first 10 results:", results_cale[:10] if len(results_cale) > 0 else "empty")
    
    latest = np.sum(TriangleCalculator.get_latest(pd.DataFrame(df_np)))
    print("latest:", latest)
    sim_diff_np = results_cale - latest
    print("sim_diff_np stats:")
    print(f"  min: {np.min(sim_diff_np)}")
    print(f"  max: {np.max(sim_diff_np)}")
    print(f"  nan count: {np.sum(np.isnan(sim_diff_np))}")

    request_id = str(uuid.uuid4())
    user_session = SESSIONS.get_session(payload.user_id)
    user_session.save_simulation(request_id, results_cale, sim_diff_np, latest)
    
    print("Creating histogram...")
    # Sprawdź czy results_cale zawiera NaN przed utworzeniem histogramu
    if np.any(np.isnan(results_cale)):
        print("WARNING: results_cale contains NaN values!")
        results_cale_clean = results_cale[~np.isnan(results_cale)]
        print(f"Cleaned results_cale shape: {results_cale_clean.shape}")
        if len(results_cale_clean) > 0:
            counts, bins = np.histogram(results_cale_clean, bins=50)
        else:
            counts, bins = np.array([]), np.array([])
    else:
        counts, bins = np.histogram(results_cale, bins=50)

    return {
        "message": "OK",
        "request_id": request_id,
        "triangle_shape": df_np.shape,
        "histogram": {
            "bins": bins.tolist(),
            "counts": counts.tolist()
        }
    }

class QuantileStochRequest(BaseModel):
    user_id: str
    request_id: str
    quantiles: List[float]

@app.post("/calc/quantiles_stoch")
async def calc_quantiles_stoch(payload: QuantileStochRequest):
    user_session = SESSIONS.get_session(payload.user_id)
    cached = user_session.get_simulation(payload.request_id)

    if cached is None:
        raise HTTPException(status_code=403, detail="Nie znaleziono danych symulacji")

    sim_results_np = cached["sim"]
    sim_diff_np = cached["diff"]

    quantiles = payload.quantiles
    values_sim = np.quantile(sim_results_np, quantiles)
    values_diff = np.quantile(sim_diff_np, quantiles)

    quantile_result = {
        str(round(q, 4)): {
            "value": float(round(v1, 2)) if np.isfinite(v1) else None,
            "value_minus_latest": float(round(v2, 2)) if np.isfinite(v2) else None
        }
        for q, v1, v2 in zip(quantiles, values_sim, values_diff)
    }

    stats = {
        "mean": {
            "value": float(np.mean(sim_results_np)),
            "value_minus_latest": float(np.mean(sim_diff_np)),
        },
        "variance": {
            "value": float(np.var(sim_results_np)),
            "value_minus_latest": float(np.var(sim_diff_np)),
        },
        "std_dev": {
            "value": float(np.std(sim_results_np)),
            "value_minus_latest": float(np.std(sim_diff_np)),
        },
        "min": {
            "value": float(np.min(sim_results_np)),
            "value_minus_latest": float(np.min(sim_diff_np)),
        },
        "max": {
            "value": float(np.max(sim_results_np)),
            "value_minus_latest": float(np.max(sim_diff_np)),
        },
    }

    return {
        "quantiles": quantile_result,
        "stats": stats
    }


class PercentileStochRequest(BaseModel):
    user_id: str
    request_id: str
    value: float
    source: str  # 'sim' lub 'diff'

@app.post("/calc/percentile_stoch")
async def calc_percentile_stoch(payload: PercentileStochRequest):
    user_session = SESSIONS.get_session(payload.user_id)
    cached = user_session.get_simulation(payload.request_id)

    if cached is None:
        raise HTTPException(status_code=404, detail="Nie znaleziono danych symulacji")

    value = payload.value
    source = payload.source

    def compute_percentile(data, val):
        sorted_data = np.sort(data)
        percentile = np.searchsorted(sorted_data, val, side='right') / len(sorted_data)
        return float(round(percentile, 6))

    if source == 'sim':
        percentile = compute_percentile(cached["sim"], value)
    elif source == 'diff':
        percentile = compute_percentile(cached["diff"], value)
    else:
        raise HTTPException(status_code=400, detail="Nieprawidłowe źródło: musi być 'sim' lub 'diff'")

    return {
        "source": source,
        "percentile": percentile
    }


###################
@app.get("/debug/endpoints")
def debug_endpoints():
    return [route.path for route in app.routes]
### boot

class WspolczynnikiBootRequest(BaseModel):
    user_id: str
    wagi_boot: List[List[int]]
    paid_data: List[List[Union[str, int, float, None]]]




@app.post("/calc/wspolczynniki_boot")
async def calc_wspolczynniki_boot(payload: WspolczynnikiBootRequest):
    print("=== DEBUG /calc/wspolczynniki_boot ===")
    print("payload.paid_data shape:", len(payload.paid_data), "x", len(payload.paid_data[0]) if payload.paid_data else 0)
    print("payload.wagi_boot shape:", len(payload.wagi_boot), "x", len(payload.wagi_boot[0]) if payload.wagi_boot else 0)
    
    paid_data = payload.paid_data
    weights = payload.wagi_boot
    print("payload.paid_data:")
    print(pd.DataFrame(paid_data).to_string())
    print("payload.wagi_boot:")
    print(pd.DataFrame(weights).to_string())

    # --- przetwarzanie danych tak samo jak w /calc/wspolczynniki_mult ---
    # UWAGA: paid_data zawiera nagłówek + pierwszą kolumnę z latami
    actual_data = paid_data[1:]  # pomiń pierwszy wiersz (nagłówek)
    data = {}
    headers = np.arange(len(actual_data[0]) - 1)  # -1 bo pomijamy pierwszą kolumnę
    
    for i, col in enumerate(headers):
        data[col] = []
        for row in actual_data:
            value = row[i + 1]  # +1 bo pomijamy pierwszą kolumnę (lata)
            try:
                num_value = float(value)
            except (ValueError, TypeError):
                num_value = None
            data[col].append(num_value)

    print("processed data:")
    print(pd.DataFrame(data).to_string())
    
    l_ij = pd.DataFrame(TriangleCalculator.elementwise_division(data))
    w_ij = pd.DataFrame(weights)
    p_ij = pd.DataFrame(data)
 
    dev_j = TriangleCalculator.Dev_prem(p_ij, w_ij)
    sigmas = TriangleCalculator.calculate_sigma(p_ij, l_ij, w_ij, dev_j)

    # --- JSON-safe (NaN/Inf -> None) ---
    def to_jsonable(x):
        arr = np.asarray(x, dtype=float)
        if arr.ndim == 0:
            return float(arr) if np.isfinite(arr) else None
        out = arr.astype(object)
        out[~np.isfinite(arr)] = None
        return out.tolist()

    return {
        "dev":   to_jsonable(dev_j),
        "sd":    to_jsonable(sigmas[0]),
        "sigma": to_jsonable(sigmas[1]),
    }


class WspolczynnikiBootParamRequest(BaseModel):
    user_id: str
    dev: List[float]
    sd: List[float]
    sigma: List[float]
    triangle: List[List[Union[str, int, float, None]]]
    wagi_boot: List[List[int]]
    sim_total: Optional[int] = 1000
    batch_sim: Optional[int] = 1000
    main_seed: Optional[int] = 202260011
    ultimate_param_resrisk: Optional[int] = 0


@app.post("/calc/obliczenia_boot_multiplikatywna")
async def obliczenia_boot_multiplikatywna(payload: WspolczynnikiBootParamRequest):
    print("=== DEBUG /calc/obliczenia_boot_multiplikatywna ===")
    print("payload.triangle shape:", len(payload.triangle), "x", len(payload.triangle[0]) if payload.triangle else 0)
    print("payload.wagi_boot shape:", len(payload.wagi_boot), "x", len(payload.wagi_boot[0]) if payload.wagi_boot else 0)
    
    wagi = pd.DataFrame(payload.wagi_boot)
    print("wagi shape:", wagi.shape)
    print("wagi:")
    print(wagi.to_string())
    
    # Przetwarzanie danych - POMIJAMY nagłówek i pierwszą kolumnę z etykietami
    triangle_data = payload.triangle[1:]  # pomijamy pierwszy wiersz (nagłówek)
    data = {}
    headers = np.arange(len(triangle_data[0]) - 1)  # -1 bo pomijamy pierwszą kolumnę
    print("headers:", headers)
    
    for i, col in enumerate(headers):
        data[col] = []
        for row in triangle_data:
            value = row[i + 1]  # +1 bo pomijamy pierwszą kolumnę (etykiety)
            try:
                num_value = float(value)
            except (ValueError, TypeError):
                num_value = 0.0  # lub None, jak preferujesz
            data[col].append(num_value)
    
    print("data keys:", list(data.keys()))
    print("data shape:", {k: len(v) for k, v in data.items()})
    
    triangle_np = np.array(list(data.values()), dtype=float).T
    print("triangle_np shape:", triangle_np.shape)
    print("triangle_np:")
    print(pd.DataFrame(triangle_np).to_string())
    
    weight_np = wagi.iloc[:(wagi.shape[0]-1), :(wagi.shape[0]-1)].to_numpy(dtype=np.float64)
    print("weight_np shape:", weight_np.shape)
    print("weight_np:")
    print(pd.DataFrame(weight_np).to_string())
    
    print("Calling run_bootstrap_monte_carlo_init...")
    print(f"  triangle_np shape: {triangle_np.shape}")
    print(f"  weight_np shape: {weight_np.shape}")
    print(f"  sim_total: {payload.sim_total}")
    
    results = TriangleCalculator.run_bootstrap_monte_carlo_init(
        triangle_np,
        weight_np,
        number_of_simulations=payload.sim_total,
        is_sigma_reestimated=False
    )
    
    print("results type:", type(results))
    print("results shape:", results.shape if hasattr(results, 'shape') else 'no shape')
    print("results stats:")
    print(f"  min: {np.min(results)}")
    print(f"  max: {np.max(results)}")
    print(f"  mean: {np.mean(results)}")
    print(f"  nan count: {np.sum(np.isnan(results))}")
    print("first 10 results:", results[:10] if len(results) > 0 else "empty")

    latest = np.sum(TriangleCalculator.get_latest(pd.DataFrame(triangle_np)))
    print("latest:", latest)
    sim_diff_np = results - latest
    print("sim_diff_np stats:")
    print(f"  min: {np.min(sim_diff_np)}")
    print(f"  max: {np.max(sim_diff_np)}")
    print(f"  nan count: {np.sum(np.isnan(sim_diff_np))}")

    request_id = str(uuid.uuid4())
    user_session = SESSIONS.get_session(payload.user_id)
    user_session.save_simulation(request_id, results, sim_diff_np, latest)

    print("Creating histogram...")
    # Sprawdź czy results zawiera NaN przed utworzeniem histogramu
    if np.any(np.isnan(results)):
        print("WARNING: results contains NaN values!")
        results_clean = results[~np.isnan(results)]
        print(f"Cleaned results shape: {results_clean.shape}")
        if len(results_clean) > 0:
            counts, bins = np.histogram(results_clean, bins=50)
        else:
            counts, bins = np.array([]), np.array([])
    else:
        counts, bins = np.histogram(results, bins=50)

    return {
        "message": "OK",
        "request_id": request_id,
        "triangle_shape": triangle_np.shape,
        "histogram": {
            "bins": bins.tolist(),
            "counts": counts.tolist()
        }
    }


@app.post("/calc/quantiles_boot")
async def calc_quantiles_boot(payload: QuantileStochRequest):
    user_session = SESSIONS.get_session(payload.user_id)
    cached = user_session.get_simulation(payload.request_id)

    if cached is None:
        raise HTTPException(status_code=403, detail="Nie znaleziono danych boot")

    sim_results_np = cached["sim"]
    sim_diff_np = cached["diff"]

    quantiles = payload.quantiles
    values_sim = np.quantile(sim_results_np, quantiles)
    values_diff = np.quantile(sim_diff_np, quantiles)

    quantile_result = {
        str(round(q, 4)): {
            "value": float(round(v1, 2)) if np.isfinite(v1) else None,
            "value_minus_latest": float(round(v2, 2)) if np.isfinite(v2) else None
        }
        for q, v1, v2 in zip(quantiles, values_sim, values_diff)
    }

    stats = {
        "mean": {
            "value": float(np.mean(sim_results_np)),
            "value_minus_latest": float(np.mean(sim_diff_np)),
        },
        "variance": {
            "value": float(np.var(sim_results_np)),
            "value_minus_latest": float(np.var(sim_diff_np)),
        },
        "std_dev": {
            "value": float(np.std(sim_results_np)),
            "value_minus_latest": float(np.std(sim_diff_np)),
        },
        "min": {
            "value": float(np.min(sim_results_np)),
            "value_minus_latest": float(np.min(sim_diff_np)),
        },
        "max": {
            "value": float(np.max(sim_results_np)),
            "value_minus_latest": float(np.max(sim_diff_np)),
        },
    }

    return {
        "quantiles": quantile_result,
        "stats": stats
    }


@app.post("/calc/percentile_boot")
async def calc_percentile_boot(payload: PercentileStochRequest):
    user_session = SESSIONS.get_session(payload.user_id)
    cached = user_session.get_simulation(payload.request_id)

    if cached is None:
        raise HTTPException(status_code=404, detail="Nie znaleziono danych boot")

    value = payload.value
    source = payload.source

    def compute_percentile(data, val):
        sorted_data = np.sort(data)
        percentile = np.searchsorted(sorted_data, val, side='right') / len(sorted_data)
        return float(round(percentile, 6))

    if source == 'sim':
        percentile = compute_percentile(cached["sim"], value)
    elif source == 'diff':
        percentile = compute_percentile(cached["diff"], value)
    else:
        raise HTTPException(status_code=400, detail="Nieprawidłowe źródło: musi być 'sim' lub 'diff'")

    return {
        "source": source,
        "percentile": percentile
    }


############ Deterministyczna

class PaidTriangleRequest(BaseModel):
    user_id: str
    paid_data_det: List[List[Union[str, int, float, None]]]
    weights: Optional[List[List[int]]] = None



class PaidCLRequest(BaseModel):
    user_id: str
    paid_data_det: List[List[Union[str, int, float, None]]]
    weights: List[List[int]]

@app.post("/calc/paid/train_devide_paid")
async def calc_paid_train_devide(payload: PaidTriangleRequest):
    data = {}
    headers = [x for x in range(len(payload.paid_data_det[0]))]
    for i, col in enumerate(headers):
        data[col] = []
        for row in payload.paid_data_det:
            value = row[i]
            try:
                num_value = float(value)
            except (ValueError, TypeError):
                num_value = None
            data[col].append(num_value)
    train_devide = TriangleCalculator.elementwise_division(data)
    print(pd.DataFrame(data).to_string())

    print(train_devide)
    train_devide_serializable = np.array(train_devide).tolist()

    print("train_devide")
    print(pd.DataFrame(train_devide_serializable).to_string())
    return {
        "train_devide": train_devide_serializable
    }


@app.post("/calc/paid/cl")
async def calc_paid_cl(payload: PaidCLRequest):
    paid_data = payload.paid_data_det
    weights = payload.weights
    print(pd.DataFrame(weights).to_string())
    print(pd.DataFrame(paid_data).to_string())

    data = {}
    headers = np.arange(len(paid_data[0]) )
 
    for i, col in enumerate(headers):
        data[col] = []
        for row in paid_data:
            value = row[i]
            try:
                num_value = float(value)
            except (ValueError, TypeError):
                num_value = None
            data[col].append(num_value)

    l_ij = pd.DataFrame(TriangleCalculator.elementwise_division(data))
    print(pd.DataFrame(l_ij).to_string())
    w_ij = pd.DataFrame(payload.weights)
    p_ij = pd.DataFrame(data)
    dev_j = TriangleCalculator.Dev_prem(p_ij,w_ij)

    print(dev_j)
    print("----")

    #sigmas = TriangleCalculator.calculate_sigma(p_ij, l_ij, w_ij, dev_j)
    ##print(sigmas[0])
    #print("----")
    #print(sigmas[1])
    #print("----")


    return {
        "message": "Odebrano dane i zastosowano wagi",
        "dev_j": list(dev_j),  # <- ważne! żeby było JSON-serializowalne
    }


class SelectedDevJRequest(BaseModel):
    user_id: Optional[str] = None
    selected_dev_j: List[float]
    selected_indexes: Optional[List[int]] = None
    tail_values: Optional[List[float]] = None
    full_dev_j: List[float]  # <= NEW

@app.post("/calc/paid/selected_dev_j")
async def receive_selected_dev_j(payload: SelectedDevJRequest):
    full_ys = np.array(payload.full_dev_j, dtype=float)  # całość
    xs = np.array(payload.selected_indexes, dtype=float) + 1
    ys = np.array(payload.selected_dev_j, dtype=float)

    curve_list = ["Exponential", "Weibull", "Power", "Inverse Power"]
    parameters_curve = calculator_det.parameters_curve_reservoir(xs=xs, ys=ys, lista_krzywych=curve_list)

    tail = int(payload.tail_values[0]) if payload.tail_values and len(payload.tail_values) > 0 else 0
    xs_sim = np.array([i + 1 for i in range(len(full_ys.tolist()) + tail)], dtype=float)
    simulation_results = calculator_det.sim_data_curve_rezerwy(xs_sim, curve_list, parameters_curve)

    f_curves_graph_real_choose = calculator_det.sim_data_curve_rezerwy(xs, curve_list, parameters_curve)
    r2_curves_df = calculator_det.r2_curves(f_curves_graph_real_choose, ys)
    print("r2_curves_df")
    print(r2_curves_df.to_dict())

    return  {
    "simulation_results": simulation_results.to_dict(),
    "r2_scores": r2_curves_df.to_dict()
}


####


# 🧩 Dane współczynników
class SaveVectorRequest(BaseModel):
    curve_name: Optional[str] = None
    coeffs: Optional[List[float]] = None
    volume: Optional[int] = None
    values: Optional[List[float]] = None
    final_dev_vector: Optional[List[float]] = None

# 🧩 Główna paczka: trójkąt + współczynniki
class SaveVectorPayload(BaseModel):
    paid_data_det: List[List[Optional[float]]]
    coeff_sets: List[SaveVectorRequest]

# 🧩 Dane współczynników
class SaveVectorRequest(BaseModel):
    curve_name: Optional[str] = None
    coeffs: Optional[List[float]] = None
    volume: Optional[int] = None
    values: Optional[List[float]] = None
    final_dev_vector: Optional[List[float]] = None

# 🧩 Główna paczka: trójkąt + współczynniki
class SaveVectorPayload(BaseModel):
    paid_data_det: List[List[Optional[float]]]
    coeff_sets: List[SaveVectorRequest]

import numpy as np
import pandas as pd
from fastapi import HTTPException

@app.post("/calc/paid/save_vector")
async def save_vector(payload: SaveVectorPayload):
    if len(payload.coeff_sets) != 2:
        raise HTTPException(status_code=400, detail="❌ Oczekiwano dokładnie 2 zestawów współczynników (A i B).")

    def extract_vector(p: SaveVectorRequest) -> List[float]:
        if p.curve_name and p.coeffs:
            return p.coeffs
        elif p.volume is not None and p.values:
            return p.values
        elif p.final_dev_vector:
            return p.final_dev_vector
        else:
            raise HTTPException(status_code=422, detail="❌ Nieprawidłowy format jednego z obiektów.")

    wektor_a = extract_vector(payload.coeff_sets[0])
    wektor_b = extract_vector(payload.coeff_sets[1])

    print("Wektor A:", wektor_a)
    print("Wektor B:", wektor_b)
    df_triangle = pd.DataFrame(payload.paid_data_det).apply(pd.to_numeric, errors='coerce')
    df_triangle = df_triangle.drop(columns='AY', errors='ignore')

    latest = TriangleCalculator.get_latest(df_triangle)

    df_proj_a = calculator_det.triangle_forward(df_triangle, wektor_a, 1)
    df_proj_b = calculator_det.triangle_forward(df_triangle, wektor_b, 1)

    last_values_a = df_proj_a.apply(lambda row: row[~row.isna()].iloc[-1], axis=1)
    last_values_b = df_proj_b.apply(lambda row: row[~row.isna()].iloc[-1], axis=1)

    diff = last_values_a - last_values_b
    percent_diff = np.where(last_values_a != 0, (diff / last_values_a) * 100, np.nan)

    projection_a_ibnr = last_values_a - latest
    projection_b_ibnr = last_values_b - latest

    diff_ibnr = projection_a_ibnr - projection_b_ibnr
    percent_diff_ibnr = np.where(projection_a_ibnr != 0, (diff_ibnr / projection_a_ibnr) * 100, 0)

    df_comparison = pd.DataFrame({
        "Wiersz": range(len(df_proj_a)),
        "Projection A": last_values_a,
        "Projection B": last_values_b,
        "Projection A IBNR": projection_a_ibnr.round(2),
        "Projection B IBNR": projection_b_ibnr.round(2),
        "Różnica": diff.round(2),
        "Różnica %": np.round(percent_diff, 2),
        "Różnica ibnr": diff_ibnr.round(2),
        "Różnica ibnr %": np.round(percent_diff_ibnr, 2),
    })

    # SUMY
    sum_a = float(last_values_a.sum())
    sum_b = float(last_values_b.sum())
    sum_diff = sum_a - sum_b
    sum_percent = (sum_diff / sum_a * 100) if sum_a != 0 else 0

    sum_a_ibnr = float(projection_a_ibnr.sum())
    sum_b_ibnr = float(projection_b_ibnr.sum())
    sum_diff_ibnr = sum_a_ibnr - sum_b_ibnr
    sum_percent_ibnr = (sum_diff_ibnr / sum_a_ibnr * 100) if sum_a_ibnr != 0 else 0

    df_comparison.loc["Suma"] = {
        "Wiersz": "Suma",
        "Projection A": sum_a,
        "Projection B": sum_b,
        "Projection A IBNR": round(sum_a_ibnr, 2),
        "Projection B IBNR": round(sum_b_ibnr, 2),
        "Różnica": round(sum_diff, 2),
        "Różnica %": None if np.isnan(sum_percent) else round(sum_percent, 2),
        "Różnica ibnr": round(sum_diff_ibnr, 2),
        "Różnica ibnr %": None if np.isnan(sum_percent_ibnr) else round(sum_percent_ibnr, 2),
    }


    print(df_comparison)
    return {
        "wektor_a": [float(x) for x in wektor_a],
        "wektor_b": [float(x) for x in wektor_b],
        "triangle_rows": int(len(payload.paid_data_det)),
        "comparison": df_comparison.to_dict(orient="records"),
    }


## incurred

class IncurredTriangleRequest(BaseModel):
    user_id: str
    incurred_data_det: List[List[Union[str, int, float, None]]]
    weights: Optional[List[List[int]]] = None


class IncurredCLRequest(BaseModel):
    user_id: str
    incurred_data_det: List[List[Union[str, int, float, None]]]
    weights: List[List[int]]

@app.post("/calc/incurred/train_devide_incurred")
async def calc_incurred_train_devide(payload: IncurredTriangleRequest):
    data = {}
    headers = [x for x in range(len(payload.incurred_data_det[0]))]
    for i, col in enumerate(headers):
        data[col] = []
        for row in payload.incurred_data_det:
            value = row[i]
            try:
                num_value = float(value)
            except (ValueError, TypeError):
                num_value = None
            data[col].append(num_value)

    train_devide = TriangleCalculator.elementwise_division(data)
    train_devide_serializable = np.array(train_devide).tolist()
    return {"train_devide": train_devide_serializable}


@app.post("/calc/incurred/cl")
async def calc_incurred_cl(payload: IncurredCLRequest):
    incurred_data = payload.incurred_data_det
    weights = payload.weights

    data = {}
    headers = np.arange(len(incurred_data[0]))
    for i, col in enumerate(headers):
        data[col] = []
        for row in incurred_data:
            value = row[i]
            try:
                num_value = float(value)
            except (ValueError, TypeError):
                num_value = None
            data[col].append(num_value)

    l_ij = pd.DataFrame(TriangleCalculator.elementwise_division(data))
    w_ij = pd.DataFrame(weights)
    p_ij = pd.DataFrame(data)
    dev_j = TriangleCalculator.Dev_prem(p_ij, w_ij)

    return {
        "message": "Odebrano dane i zastosowano wagi",
        "dev_j": list(dev_j),
    }



class SelectedDevJRequest(BaseModel):
    user_id: Optional[str] = None
    selected_dev_j: List[float]
    selected_indexes: Optional[List[int]] = None
    tail_values: Optional[List[float]] = None
    full_dev_j: List[float]            # pełen wektor dev_j

# -------------------------------------------------------------------
# ENDPOINT – istniejący (Paid) NIE zmieniamy
# -------------------------------------------------------------------
@app.post("/calc/paid/selected_dev_j")
async def calc_paid_selected_dev_j(payload: SelectedDevJRequest):
    return _process_selected_dev_j(payload)   # <‑‑ patrz funkcja pomocnicza


# -------------------------------------------------------------------
# ENDPOINT – NOWY wariant Incurred
# -------------------------------------------------------------------
@app.post("/calc/incurred/selected_dev_j")
async def calc_incurred_selected_dev_j(payload: SelectedDevJRequest):
    return _process_selected_dev_j(payload)   # logika współdzielona


# -------------------------------------------------------------------
# WSPÓLNA FUNKCJA POMOCNICZA
# -------------------------------------------------------------------
def _process_selected_dev_j(payload: SelectedDevJRequest):
    """
    Wspólna logika dla wariantów Paid / Incurred.
    """
    # ▸ wektor pełny
    full_ys = np.array(payload.full_dev_j, dtype=float)

    # ▸ punkty wybrane przez użytkownika
    xs = np.array(payload.selected_indexes or [], dtype=float) + 1  # indeksy 1‑based
    ys = np.array(payload.selected_dev_j, dtype=float)

    # ▸ dopasowanie krzywych
    curve_list = ["Exponential", "Weibull", "Power", "Inverse Power"]
    parameters_curve = calculator_det.parameters_curve_reservoir(
        xs=xs, ys=ys, lista_krzywych=curve_list
    )

    # ▸ symulacja
    tail = int(payload.tail_values[0]) if payload.tail_values else 0
    xs_sim = np.array([i + 1 for i in range(len(full_ys) + tail)], dtype=float)
    simulation_results = calculator_det.sim_data_curve_rezerwy(
        xs_sim, curve_list, parameters_curve
    )

    # ▸ R²
    f_curves_graph_real_choose = calculator_det.sim_data_curve_rezerwy(
        xs, curve_list, parameters_curve
    )
    r2_curves_df = calculator_det.r2_curves(f_curves_graph_real_choose, ys)

    return {
        "simulation_results": simulation_results.to_dict(),
        "r2_scores": r2_curves_df.to_dict(),
    }



class SaveVectorRequest(BaseModel):
    curve_name:        Optional[str]        = None   # symulowana krzywa CL
    coeffs:            Optional[List[float]] = None  # ⬆ jej współczynniki
    volume:            Optional[int]         = None  # dev_j z konkretnego volume
    values:            Optional[List[float]] = None  # ⬆ jego wektor dev_j
    final_dev_vector:  Optional[List[float]] = None  # gotowy dev_final / combined


# ──────────────────────────────────────────────────────────────────────────────
#  2. Cały payload: trójkąt incurred + dokładnie 2 zestawy współczynników
# ──────────────────────────────────────────────────────────────────────────────
class SaveVectorPayload(BaseModel):
    incurred_data_det: List[List[Optional[float]]]
    coeff_sets:        List[SaveVectorRequest]


# ──────────────────────────────────────────────────────────────────────────────
#  3. Pomocnicza funkcja – wyciąga wektor z SaveVectorRequest
# ──────────────────────────────────────────────────────────────────────────────
def _extract_vector(p: SaveVectorRequest) -> List[float]:
    if p.curve_name and p.coeffs:
        return p.coeffs
    if p.volume is not None and p.values:
        return p.values
    if p.final_dev_vector:
        return p.final_dev_vector
    raise HTTPException(
        status_code=422,
        detail="❌ Nieprawidłowy format jednego z obiektów (brak danych wektora).",
    )


# ──────────────────────────────────────────────────────────────────────────────
#  4. Endpoint  POST /calc/incurred/save_vector
# ──────────────────────────────────────────────────────────────────────────────
@app.post("/calc/incurred/save_vector")
async def save_vector_incurred(payload: SaveVectorPayload):
    # 1) Walidacja liczby zestawów
    if len(payload.coeff_sets) != 2:
        raise HTTPException(
            status_code=400,
            detail="❌ Oczekiwano dokładnie 2 zestawów współczynników (A i B).",
        )

    # 2) Wektory A/B (jak u Ciebie – wspólna funkcja pomocnicza)
    vector_a = _extract_vector(payload.coeff_sets[0])
    vector_b = _extract_vector(payload.coeff_sets[1])

    
    # 3) Trójkąt INCURRED
    df_triangle = (
        pd.DataFrame(payload.incurred_data_det)
        .apply(pd.to_numeric, errors="coerce")
        .drop(columns="AY", errors="ignore")
    )

    # 4) Najnowsza przekątna (observed-to-date)
    latest = TriangleCalculator.get_latest(df_triangle)

    # 5) Projekcje A/B
    df_proj_a = calculator_det.triangle_forward(df_triangle, vector_a, 1)
    df_proj_b = calculator_det.triangle_forward(df_triangle, vector_b, 1)

    # 6) Ostatnie nie-NaN w wierszu
    last_a = df_proj_a.apply(lambda r: r[~r.isna()].iloc[-1], axis=1)
    last_b = df_proj_b.apply(lambda r: r[~r.isna()].iloc[-1], axis=1)

    # 7) Różnice i % (projekcje)
    diff_abs = last_a - last_b
    diff_pct = np.where(last_a != 0, (diff_abs / last_a) * 100, np.nan)

    # 8) IBNR = projekcja - latest
    proj_a_ibnr = last_a - latest
    proj_b_ibnr = last_b - latest

    diff_ibnr = proj_a_ibnr - proj_b_ibnr
    diff_ibnr_pct = np.where(proj_a_ibnr != 0, (diff_ibnr / proj_a_ibnr) * 100, 0)

    # 9) Tabela porównania (tak jak w paid)
    df_comparison = pd.DataFrame({
        "Wiersz": range(len(df_proj_a)),
        "Projection A": last_a,
        "Projection B": last_b,
        "Projection A IBNR": proj_a_ibnr.round(2),
        "Projection B IBNR": proj_b_ibnr.round(2),
        "Różnica": diff_abs.round(2),
        "Różnica %": np.round(diff_pct, 2),
        "Różnica ibnr": diff_ibnr.round(2),
        "Różnica ibnr %": np.round(diff_ibnr_pct, 2),
    })

    # 10) SUMA (jak w paid)
    sum_a = float(last_a.sum())
    sum_b = float(last_b.sum())
    sum_diff = sum_a - sum_b
    sum_percent = (sum_diff / sum_a * 100) if sum_a != 0 else 0

    sum_a_ibnr = float(proj_a_ibnr.sum())
    sum_b_ibnr = float(proj_b_ibnr.sum())
    sum_diff_ibnr = sum_a_ibnr - sum_b_ibnr
    sum_percent_ibnr = (sum_diff_ibnr / sum_a_ibnr * 100) if sum_a_ibnr != 0 else 0

    df_comparison.loc["Suma"] = {
        "Wiersz": "Suma",
        "Projection A": round(sum_a, 2),
        "Projection B": round(sum_b, 2),
        "Projection A IBNR": round(sum_a_ibnr, 2),
        "Projection B IBNR": round(sum_b_ibnr, 2),
        "Różnica": round(sum_diff, 2),
        "Różnica %": None if np.isnan(sum_percent) else round(sum_percent, 2),
        "Różnica ibnr": round(sum_diff_ibnr, 2),
        "Różnica ibnr %": None if np.isnan(sum_percent_ibnr) else round(sum_percent_ibnr, 2),
    }

    print(df_comparison)  # ewentualny debug

    return {
        "wektor_a": [float(x) for x in vector_a],
        "wektor_b": [float(x) for x in vector_b],
        "triangle_rows": int(len(payload.incurred_data_det)),
        "comparison": df_comparison.to_dict(orient="records"),
    }



# porownanie wynikow #########################

class SaveVectorRequest(BaseModel):
    curve_name:        Optional[str]   = None
    coeffs:            Optional[List[float]] = None
    volume:            Optional[int]   = None
    values:            Optional[List[float]] = None
    final_dev_vector:  Optional[List[float]] = None


# ==================================================================================
# 2️⃣  NOWY  model ładujący  ⟶  Paid + Incurred  razem
# ==================================================================================
class SaveSummaryPayload(BaseModel):
    paid_data_det:     List[List[Optional[float]]]
    incurred_data_det: List[List[Optional[float]]]

    paid_coeff_set:     SaveVectorRequest
    incurred_coeff_set: SaveVectorRequest


# ==================================================================================
# 3️⃣  HELPER – zamienia SaveVectorRequest → wektor  (ta sama logika co wcześniej)
# ==================================================================================
from fastapi import HTTPException

def extract_vector(req: SaveVectorRequest) -> List[float]:
    if req.curve_name and req.coeffs:
        return req.coeffs
    elif req.volume is not None and req.values:
        return req.values
    elif req.final_dev_vector:
        return req.final_dev_vector
    else:
        raise HTTPException(
            status_code=422,
            detail="❌ Nieprawidłowy format obiektu współczynników.",
        )


# ==================================================================================
# 4️⃣  ENDPOINT  POST /calc/summary/save_vector
# ==================================================================================
from fastapi import status

@app.post("/calc/summary/save_vector", status_code=status.HTTP_201_CREATED)
async def save_summary_vector(payload: SaveSummaryPayload):

    # ─── 1. wyciągamy wektory ────────────────────────────────────────
    try:
        vec_paid = _extract_vector(payload.paid_coeff_set)
        vec_inc  = _extract_vector(payload.incurred_coeff_set)
    except HTTPException as e:
        raise e

    # ─── 2. DataFrame’y z trójkątów ─────────────────────────────────
    df_paid = (
        pd.DataFrame(payload.paid_data_det)
        .apply(pd.to_numeric, errors="coerce")
        .drop(columns="AY", errors="ignore")
    )
    df_inc = (
        pd.DataFrame(payload.incurred_data_det)
        .apply(pd.to_numeric, errors="coerce")
        .drop(columns="AY", errors="ignore")
    )

    # ─── 3. projekcje dla każdego z osobna ──────────────────────────
    proj_paid = calculator_det.triangle_forward(df_paid, vec_paid, 1)
    proj_inc  = calculator_det.triangle_forward(df_inc,  vec_inc,  1)



    last_paid = proj_paid.apply(lambda r: r.dropna().iloc[-1], axis=1)
    last_inc  = proj_inc.apply(lambda r: r.dropna().iloc[-1], axis=1)

 

    sum_paid = last_paid.sum()
    sum_inc  = last_inc.sum()

    df_two = pd.DataFrame(
        {
            "Paid":     last_paid.round(2),
            "Incurred": last_inc.round(2),
        }
    )

    return {
        "triangle_paid"     : payload.paid_data_det,
        "triangle_incurred" : payload.incurred_data_det,
        "vec_paid"          : vec_paid,
        "vec_incurred"      : vec_inc,
        "comparison"        : df_two.to_dict(orient="records"),   # ⬅️ tylko 2 kolumny
    }



#################################


from sklearn.linear_model import LinearRegression
from statsmodels.nonparametric.smoothers_lowess import lowess
from pydantic import BaseModel, Field

from scipy.stats import spearmanr, norm


class TriangleInput(BaseModel):
    triangle: List[List[Optional[float]]]
    alpha: float = Field(1.0, ge=0.0, le=2.0)
    ci: float = Field(0.5, ge=0.01, le=0.99)

# 📊 Endpoint 1 – analiza residuals i LOWESS
@app.post("/analyze-residuals")
def analyze_residuals(data: TriangleInput):
    max_len = max(len(row) for row in data.triangle)
    padded = [row + [np.nan] * (max_len - len(row)) for row in data.triangle]
    tri_arr = np.array(padded, dtype=float)
    tri_df = pd.DataFrame(
        tri_arr,
        index=np.arange(1, tri_arr.shape[0] + 1),
        columns=np.arange(1, tri_arr.shape[1] + 1),
    )

    alpha = data.alpha
    delta = 2 - alpha

    fitted_values, origin_periods, dev_periods, actual_vals, std_residuals = (
        [] for _ in range(5)
    )

    for j in range(tri_df.shape[1] - 1):
        x_col, y_col = tri_df.iloc[:, j], tri_df.iloc[:, j + 1]
        valid = ~(x_col.isna() | y_col.isna())

        x = x_col[valid].to_numpy(dtype=float).reshape(-1, 1)
        y = y_col[valid].to_numpy(dtype=float)
        w = 1 / np.power(x.flatten(), delta)

        lr = LinearRegression(fit_intercept=False)
        lr.fit(x, y, sample_weight=w)

        y_hat = lr.predict(x)
        residuals = y - y_hat
        rss_w = np.sum(w * residuals**2)
        n = len(y)

        if n > 1:
            sigma = np.sqrt(rss_w / (n - 1))
            S = np.sum(w * (x.flatten() ** 2))
            h = w * (x.flatten() ** 2) / S
            stud_resid = residuals * np.sqrt(w) / (sigma * np.sqrt(1 - h))
        else:
            stud_resid = np.full_like(y, np.nan)

        fitted_values.extend(y_hat)
        origin_periods.extend(x_col.index[valid])
        dev_periods.extend([j + 1] * n)
        actual_vals.extend(y)
        std_residuals.extend(stud_resid)

    residuals_raw = np.array(actual_vals) - np.array(fitted_values)

    obs_vs_fitted = pd.DataFrame({
        "origin_period": origin_periods,
        "dev_period": np.array(dev_periods),
        "cal_period": np.array(origin_periods) + np.array(dev_periods) - 1,
        "residuals": residuals_raw,
        "standard_residuals": std_residuals,
        "fitted_value": fitted_values,
    }).dropna().reset_index(drop=True)

    lowess_results = {
        "fitted_value": pd.DataFrame(lowess(obs_vs_fitted["standard_residuals"], obs_vs_fitted["fitted_value"], frac=2/3), columns=["x", "lowess"]),
        "origin_period": pd.DataFrame(lowess(obs_vs_fitted["standard_residuals"], obs_vs_fitted["origin_period"], frac=2/3), columns=["x", "lowess"]),
        "cal_period": pd.DataFrame(lowess(obs_vs_fitted["standard_residuals"], obs_vs_fitted["cal_period"], frac=2/3), columns=["x", "lowess"]),
        "dev_period": pd.DataFrame(lowess(obs_vs_fitted["standard_residuals"], obs_vs_fitted["dev_period"], frac=2/3), columns=["x", "lowess"]),
    }

    return {
        "obs_vs_fitted": obs_vs_fitted.to_dict(orient="records"),
        "lowess_results": {
            k: v.to_dict(orient="records") for k, v in lowess_results.items()
        },
    }

# 📈 Endpoint 2 – analiza zależności
@app.post("/analyze-dependence")
def analyze_dependence(data: TriangleInput):
    triangle = np.array(data.triangle, dtype=np.float64)
    ci = data.ci

    print(ci)
    n_rows, n_cols = triangle.shape
    ata = np.full((n_rows, n_cols - 1), np.nan)

    for i in range(n_rows):
        for j in range(n_cols - 1):
            if not np.isnan(triangle[i, j]) and not np.isnan(triangle[i, j + 1]) and triangle[i, j] != 0:
                ata[i, j] = triangle[i, j + 1] / triangle[i, j]

    T_k = []
    for i in range(n_cols - 3):
        col1 = ata[:, i]
        col2 = ata[:, i + 1]
        valid = ~np.isnan(col1) & ~np.isnan(col2)
        if np.sum(valid) > 1:
            rho, _ = spearmanr(col1[valid], col2[valid])
            T_k.append(rho)

    if len(T_k) > 0:
        weights = np.arange(len(T_k), 0, -1)
        T_final = np.average(T_k, weights=weights)
        Var_T = 1 / ((n_cols - 2) * (n_cols - 3) / 2)
        Z = norm.ppf(ci + (1 - ci) / 2)
        range_ = [-Z * np.sqrt(Var_T), Z * np.sqrt(Var_T)]
    else:
        T_final = None
        Var_T = None
        range_ = [None, None]

    # 🔷 Gęstość do wykresu
    density_data = None
    if T_final is not None and Var_T is not None:
        sd = np.sqrt(Var_T)

        # Krzywa normalna (pełna)
        x_seq = np.linspace(-1, 1, 500)  # 500 punktów dla lepszej gładkości
        y_seq = norm.pdf(x_seq, loc=0, scale=sd)
        # Obszar pod przedziałem ufności (zacieniowany)
        ci_x = np.arange(range_[0], range_[1], 0.01)
        ci_y = norm.pdf(ci_x, loc=0, scale=sd)

        density_data = {
            "curve": list(zip(x_seq, y_seq)),
            "ci_area": list(zip(ci_x, ci_y)),
            "T_stat": T_final,
            "T_y": norm.pdf(T_final, loc=0, scale=sd)
        }

    return {
        "T_stat": T_final,
        "Var": Var_T,
        "Range": range_,
        "ci": ci,
        "summary": {
            "results": {
                "T": T_final,
                "E[T]": 0,
                "Var[T]": Var_T
            },
            "range": {
                "Lower": range_[0],
                "Upper": range_[1]
            }
        },
        "density_plot": density_data
    }

from math import comb, sqrt
class AnalyzeDep2Request(BaseModel):
    triangle: List[List[Optional[float]]]
    ci: float = 0.95

class DensityPlot(BaseModel):
    curve:  list[tuple[float, float]]
    ci_area:list[tuple[float, float]]
    Z_stat: float
    Z_y:    float

class AnalyzeDep2Response(BaseModel):
    totals: dict[str, float]       # albo Dict[str, float]
    range:  dict[str, float]
    ci: float
    density_plot: Optional[DensityPlot] = None
# ------------------------------------------------------------------ #


# ------------------------------------------------------------------ #
#  LOGIKA                                                            #
# ------------------------------------------------------------------ #

def calendar_year_effect(triangle: List[List[Optional[float]]],
                         ci: float = 0.95) -> AnalyzeDep2Response:
    if not (0 < ci < 1):
        raise ValueError("ci must be between 0 and 1")

    tri = np.array(triangle, dtype=float)
    n_rows, n_cols = tri.shape

    # Cumulative triangle (jeśli dane już są cumulative, ta linia nie szkodzi)
    cum_tri = np.array(tri)

    ata = np.full((n_rows, n_cols - 1), np.nan)
    for i in range(n_rows):
        for j in range(n_cols - 1):
            if not np.isnan(cum_tri[i, j]) and not np.isnan(cum_tri[i, j + 1]) and cum_tri[i, j] != 0:
                ata[i, j] = cum_tri[i, j + 1] / cum_tri[i, j]

    col_medians = np.nanmedian(ata, axis=0)
    S_L = np.where(ata < col_medians, "S",
           np.where(ata > col_medians, "L", "*"))

    # *** KLUCZOWA LINIA – przekątne calendar year (zgodne z Mackiem i R) ***
    diags = [np.diag(S_L[:i, :i][:, ::-1]) for i in range(2, n_rows)]

    Z_tot = E_tot = Var_tot = 0.0
    for d in diags:
        S_j = np.sum(d == "S")
        L_j = np.sum(d == "L")
        n_j = S_j + L_j
        m_j = (n_j - 1) // 2
        Z_j = min(S_j, L_j)
        Z_tot += Z_j

        if n_j > 0:
            E_j  = n_j / 2 - comb(n_j - 1, m_j) * n_j / 2 ** n_j
            Var_j = (n_j * (n_j - 1) / 4
                     - comb(n_j - 1, m_j) * n_j * (n_j - 1) / 2 ** n_j
                     + E_j - E_j ** 2)
        else:
            E_j = Var_j = 0
        E_tot  += E_j
        Var_tot += Var_j

    z_score = norm.ppf(ci + (1 - ci) / 2)
    rng_low = E_tot - z_score * sqrt(Var_tot)
    rng_up  = E_tot + z_score * sqrt(Var_tot)

    # --------- krzywa gęstości (jak w R‑owym plot) -----------------
    sd       = sqrt(Var_tot)
    x_seq    = np.linspace(E_tot - 4*sd, E_tot + 4*sd, 500)
    y_seq    = norm.pdf(x_seq, loc=E_tot, scale=sd)

    ci_x     = np.arange(rng_low, rng_up, 0.01)
    ci_y     = norm.pdf(ci_x, loc=E_tot, scale=sd)

    density  = DensityPlot(
        curve    = list(zip(x_seq.tolist(), y_seq.tolist())),
        ci_area  = list(zip(ci_x.tolist(), ci_y.tolist())),
        Z_stat   = float(Z_tot),
        Z_y      = float(norm.pdf(Z_tot, loc=E_tot, scale=sd))
    )
    # ---------------------------------------------------------------

    return AnalyzeDep2Response(
        totals = {
            "Z":      round(Z_tot, 4),
            "E[Z]":   round(E_tot, 4),
            "Var[Z]": round(Var_tot, 4)
        },
        range  = {
            "Lower":  round(rng_low, 4),
            "Upper":  round(rng_up, 4)
        },
        ci = ci,
        density_plot = density
    )

# ------------------------------------------------------------------ #
#  ENDPOINT                                                          #
# ------------------------------------------------------------------ #
@app.post("/analyze-dep2", response_model=AnalyzeDep2Response)
def analyze_dep2(req: AnalyzeDep2Request):

    return calendar_year_effect(req.triangle, ci=req.ci)




###########################
