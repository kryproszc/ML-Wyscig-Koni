
from typing import Iterable, Sequence
import time

import numpy as np
import pandas as pd
from numba import njit, prange

# ---------------------------------------------------------------------------
# Helper functions (Numba‑accelerated)
# ---------------------------------------------------------------------------
from numba import njit, prange
@njit
def vector_reverse_diagonal(data: np.ndarray):
    """Zwraca wektor elementów odwrotnej przekątnej (ostatniej pełnej diagonali)."""
    rows, cols = data.shape
    result = []
    for i in range(rows):
        j = cols - 1 - i
        if 0 <= j < cols:
            v = data[i, j]
            if not np.isnan(v):
                result.append(v)
    return np.array(result)

@njit
def sum_reverse_diagonal(data: np.ndarray) -> float:
    """Suma odwrotnej przekątnej (ostatniej pełnej diagonali)."""
    tot = 0.0
    rows, cols = data.shape
    for i in range(rows):
        j = cols - 1 - i
        if 0 <= j < cols:
            v = data[i, j]
            if not np.isnan(v):
                tot += v
    return tot


@njit
def Dev_prem(data_paid: np.ndarray, wagi: np.ndarray) -> np.ndarray:
    n_row, n_col = data_paid.shape
    dev = np.empty(n_col - 1)
    for j in range(n_col - 1):
        num = den = 0.0
        for i in range(n_row):
            val_curr = data_paid[i, j]
            val_next = data_paid[i, j + 1]
            w = wagi[i, j]
            if not (np.isnan(val_next)):
                num += val_next * w
                den += val_curr * w
        dev[j] = num / den if den != 0.0 else 1.0
    return dev


@njit
def elementwise_division(data_paid: np.ndarray) -> np.ndarray:

    n_rows, n_cols = data_paid.shape
    out = np.empty((n_rows, n_cols - 1))
    for i in range(n_rows):
        for j in range(n_cols - 1):
            a = data_paid[i, j]
            b = data_paid[i, j + 1]
            if a != 0.0 and not np.isnan(b):
                val = b / a
                out[i, j] = val if np.isfinite(val) else 1.0
            else:
                out[i, j] = 1.0
    return out

@njit
def calculate_sigma(p_ij, l_ij, w_ij, dev_j):
    n_rows, n_cols = l_ij.shape
    sigmas = np.empty(n_cols)
    sds = np.empty(n_cols)
    for j in range(n_cols):
        dev = dev_j[j]
        num = den = den_sd = 0.0
        cnt = 0
        for i in range(n_rows - 1):
            w = w_ij[i, j]
            p = p_ij[i, j]
            l = l_ij[i, j]
            if not (np.isnan(w)):
                diff = l - dev
                num += w * p * diff * diff
                den += w
                den_sd += w * p
                cnt += 1
        sigma = num / (den - 1.0) if  den > 1.0 else sigmas[j-1]
        sd_val = sigma / den_sd if den_sd > 0.0 else sds[j-1]
        sigmas[j] = sigma
        sds[j] = np.sqrt(sd_val)
    return sigmas, sds


from numba import njit

@njit
def choose_value_list(vec_input, vec_wykluczenia, a, b):
    count = 0
    for k in range(len(vec_wykluczenia)):
        idx = vec_wykluczenia[k] - 1
        val = vec_input[idx]
        if a < val < b:
            count += 1

    out_vals = np.empty(count)
    out_inds = np.empty(count, dtype=np.int64)

    pos = 0
    for k in range(len(vec_wykluczenia)):
        idx = vec_wykluczenia[k] - 1
        val = vec_input[idx]
        if a < val < b:
            out_vals[pos] = val
            out_inds[pos] = idx
            pos += 1

    return out_vals, out_inds

@njit
def fit_curve_factor_cl(data_input, sd_input, x_k):
    n = len(data_input)
    se2 = sd_input **2
    w = np.empty(n)
    for i in range(n):
        denom = (data_input[i] - 1) ** 2
        w[i] = 1.0 / np.sqrt(np.log(1.0 + se2[i] / denom)) if denom > 0.0 else 0
    y = np.log(data_input - 1.0)
    A = A_x = A_xx = A_y = A_xy = 0.0
    for i in range(n):
        wi = w[i]
        xi = x_k[i]
        yi = y[i]
        A += wi
        A_x += wi * xi
        A_xx += wi * xi * xi
        A_y += wi * yi
        A_xy += wi * xi * yi
    Delta = A * A_xx - A_x * A_x
    if Delta == 0.0:
        return 0.0, 0.0
    a_coef = (A * A_xy - A_x * A_y) / Delta
    b_coef = (A_xx * A_y - A_x * A_xy) / Delta
    return a_coef, b_coef

@njit
def wspolczynnik_reg_factor_cl(a_coef, b_coef, k_start, k_stop):
    n = k_stop - k_start + 1
    out = np.empty(n)
    for i in range(n):
        k = k_start + i
        out[i] = 1.0 + np.exp(a_coef * k + b_coef)
    return out


@njit
def triangle_forward_one_np(triangle_input, f, k_forward_start):
    mm, nn = triangle_input.shape
    req_cols = len(f) + 1
    tri = np.zeros((mm, req_cols))
    # kopiuj istniejące dane
    for i in range(mm):
        for j in range(nn):
            tri[i, j] = triangle_input[i, j]
    # projekcja
    for j in range(k_forward_start - 1, len(f)):
        if j + 1 >= req_cols:
            continue
        max_row = max(0, mm - j - 1)
        for i in range(max_row, mm):
            tri[i, j + 1] = tri[i, j] * f[j]
    return tri


# ---------------------------------------------------------------------------
# Monte‑Carlo engine (Numba parallel)
# ---------------------------------------------------------------------------
@njit
def add_first(arr, val):
    return np.concatenate((np.array([val]), arr))
@njit
def stochastic_triangle_forward_numba_batched(
    data_paid,
    sigma_j,
    dev,
    sd,
    wagi_trimmed,
    wykluczenia,
    Poz_CL,
    il_ogon,
    discount_factors,
    net_to_gross,
    latest,
    sim_total=100_000,
    batch_sim=1_000,
    main_seed=202260011,
):
    """Zwraca macierz (sim_total, 3): gross, gross_disc, net_disc."""
    mm, n_cols_orig = data_paid.shape
    n_dev = len(dev)
    results = np.zeros((sim_total, 3))
    n_batches = sim_total // batch_sim

    for batch_idx in prange(n_batches):
        np.random.seed(main_seed + batch_idx)
        mu_part = np.empty((batch_sim, n_dev))
        sigma_part = np.empty((batch_sim, n_dev))

        # ---- parameter risk
        for j in range(n_dev):
            mu_part[:, j] = np.random.normal(dev[j], sd[j], batch_sim)
            df = max(1, mm - j - 2)
            chi = np.random.chisquare(df, batch_sim)
            for s in range(batch_sim):
                sigma_part[s, j] = (np.floor(chi[s]) * sigma_j[j]) / df

        # ---- process risk
        for i in range(batch_sim):
            m_i = mu_part[i]
            s_i = sigma_part[i]

            n_cols_target = n_dev + 1
            tri_copy = np.zeros((mm, n_cols_target))
            new_tri = np.zeros((mm, n_cols_target))
            for rr in range(mm):
                for c in range(n_cols_orig):
                    v = data_paid[rr, c]
                    tri_copy[rr, c] = v
                    new_tri[rr, c] = v
            empty_row = np.full((1, wagi_trimmed.shape[1]), np.nan)
            wagi_modified_row = np.vstack((wagi_trimmed, empty_row))
            empty_column = np.full((wagi_modified_row.shape[0], 1), np.nan)
            wagi_modified = np.hstack((wagi_modified_row, empty_column))

            for j in range(n_dev):
                max_row = max(1, mm - j)
                for r in range(max_row - 1, mm):
                    base = tri_copy[r, j]
                    if base>0:
                        var_ij = s_i[j] / base
                        m2 = m_i[j] ** 2
                        denom = np.sqrt(m2 + var_ij)
                        ln_mean = np.log(m2 / denom)
                        ln_sd = np.sqrt(np.log(1.0 + var_ij / m2))
                        cl_factor = np.random.lognormal(ln_mean, ln_sd)
                        tri_copy[r, j + 1] = base * cl_factor
                        dev_con = m_i[j]
                        std_con = np.sqrt(var_ij)
                        if r == mm - j - 1:
                            new_tri[r, j + 1] = base * cl_factor
                        if r == mm - j - 1 and (j<(mm)):
                            if dev_con - 2 * std_con <= cl_factor <= dev_con + 2 * std_con:
                                wagi_modified[r,j] = 1
                            elif (dev_con - 3 * std_con <= cl_factor < dev_con - 2 * std_con) or (dev_con +2 * std_con < cl_factor <= dev_con + 3 * std_con):
                                wagi_modified[r,j] = 0.5
                            else:
                                wagi_modified[r,j] = 0
                    else:
                        tri_copy[r, j + 1] = 0
                        if r == mm - j - 1:
                            new_tri[r, j + 1] = base * cl_factor
                            wagi_modified[r,j] = 0


            new_tri[1:,  n_cols_orig ] = np.nan
            tri_sim = new_tri[:, 1 : (n_cols_orig + 1)]
            dev_j = Dev_prem(new_tri[:,  :(n_cols_orig + 1)], wagi_modified)
            l_ij = elementwise_division(new_tri[:,  :(n_cols_orig + 1)])
            sigma_all = calculate_sigma(new_tri[:, :(n_cols_orig + 1)], l_ij, wagi_modified, dev_j)
            sd_sim = sigma_all[1]
            dev_sel,ind_choode = choose_value_list(dev_j, np.array(wykluczenia),1,10)
            sd_sel = sd_sim[ind_choode]
            x_k = ind_choode+1
            a_coef, b_coef = fit_curve_factor_cl(dev_sel, sd_sel, x_k)
            total_f_len = len(dev_j) + il_ogon
            if Poz_CL-1>0:
                vec_f = np.empty(total_f_len-1 )
                vec_f[:(Poz_CL - 1)] = dev_j[1:(Poz_CL)]
                vec_f[(Poz_CL-1):] = wspolczynnik_reg_factor_cl(
                    a_coef, b_coef,
                    Poz_CL+1,
                    total_f_len
                )
            else:
                vec_f = wspolczynnik_reg_factor_cl(
                    a_coef, b_coef,
                    2,
                    total_f_len
                )
            tri_proj_tmp = triangle_forward_one_np(tri_sim, vec_f, 1)[:,:-1]


            cols_tmp = tri_proj_tmp.shape[1]
            tri_proj = np.empty((mm, cols_tmp + 1))
            tri_proj[:, 0] = data_paid[:, 0]
            for r in range(mm):
                for c in range(cols_tmp):
                    tri_proj[r, c + 1] = tri_proj_tmp[r, c]
            inc_proj = tri_proj[:, 1:] - tri_proj[:, :-1]
            inc_disc = np.empty_like(tri_proj)
            inc_disc[:, 0] = tri_proj[:, 0]
            for r in range(mm):
                for c in range(1, tri_proj.shape[1]):
                    inc_disc[r, c] = inc_proj[r, c - 1]
            for rr in range(mm - 1, -1, -1):
                offset = mm - 1 - rr
                for cc in range(offset + 1, tri_proj.shape[1]):
                    idx = cc - (offset + 1)
                    if idx < len(discount_factors):
                        inc_disc[rr, cc] /= discount_factors[idx]
            cum_disc = inc_disc.copy()
            for r in range(mm):
                for c in range(1, tri_proj.shape[1]):
                    cum_disc[r, c] += cum_disc[r, c - 1]
            ult_gross_disc = np.sum(cum_disc[:, n_cols_target - 1])

            cum_trian_ost = cum_disc[:, n_cols_target - 1]

            ult_net_disc = 0

            for iii in range(len(latest)):
                ult_net_disc += latest[iii] + (cum_trian_ost[iii] - latest[iii]) * net_to_gross[iii]

           # ult_net_disc = latest + (ult_gross_disc - latest) * net_to_gross
            ult_gross = np.sum(tri_copy[:, n_cols_target - 1])
            idx_out = int(batch_idx * batch_sim + i)  # cast na int
            results[idx_out, 0] = ult_gross
            results[idx_out, 1] = ult_gross_disc
            results[idx_out, 2] = ult_net_disc

    return results


class YearHorizont2:
    def run_simulation_cl(self,
    data_paid,
    sigma_j,
    dev,
    sd,
    wagi_trimmed,
    wykluczenia,
    Poz_CL,
    il_ogon,
    discount_factors,
    net_to_gross,
    latest,
    sim_total=100_000,
    batch_sim=1_000,
    main_seed=202260011):

        return stochastic_triangle_forward_numba_batched(
            data_paid,
            sigma_j,
            dev,
            sd,
            wagi_trimmed,
            wykluczenia,
            Poz_CL,
            il_ogon,
            discount_factors,
            net_to_gross,
            latest,
            sim_total,
            batch_sim,
            main_seed
        )

    def vector_reverse_diagonal_to_script(self,data):
        return vector_reverse_diagonal(data)
        



    def triangle_forward_np(self, data, f, k_forward_start, discount_factors,net_to_gross):
        data = data.copy()
        mm, nn = data.shape
        latest = self.vector_reverse_diagonal_to_script(data)
        # Zachowujemy oryginalną pierwszą kolumnę
        base_col = data[:, 0].copy()

        # Rozszerz dane, jeśli trzeba
        if len(f) > mm:
            pad_width = len(f) + 1 - nn
            if pad_width > 0:
                data = np.hstack((data, np.full((mm, pad_width), np.nan)))

        # Projekcja forward
        for j in range(k_forward_start - 1, len(f)):
            max_ind_row = max(0, mm - j - 1)
            for i in range(max_ind_row, mm):
                data[i, j + 1] = data[i, j] * f[j]

        # Tworzenie trójkąta z bazową kolumną
        cols_tmp = data.shape[1]
        tri_proj = np.full((mm, cols_tmp + 1), np.nan)
        tri_proj[:, 0] = base_col
        tri_proj[:, 1:] = data

        inc_proj = tri_proj[:, 1:] - tri_proj[:, :-1]
        inc_proj[:, 0] = base_col


        for rr in range(mm - 1, -1, -1):
            offset = mm - 1 - rr
            for cc in range(offset + 1, inc_proj.shape[1]):
                idx = cc - (offset + 1)
                if idx < len(discount_factors) and not np.isnan(inc_proj[rr, cc]):
                    inc_proj[rr, cc] /=discount_factors[idx]
        cum_trian = np.nansum(inc_proj, axis=1)
        total_disc = np.sum(cum_trian)

        ult_net_disc = 0


        for i in range(len(latest)):
            ult_net_disc += latest[i] +(cum_trian[i] - latest[i])*net_to_gross[i]



        return [np.sum(data[:,-1]),total_disc,ult_net_disc ]

