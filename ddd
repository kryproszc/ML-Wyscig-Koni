

from sklearn.linear_model import LinearRegression
from statsmodels.nonparametric.smoothers_lowess import lowess
from pydantic import BaseModel, Field

from scipy.stats import spearmanr, norm


class TriangleInput(BaseModel):
    triangle: List[List[Optional[float]]]
    alpha: float = Field(1.0, ge=0.0, le=2.0)
    ci: float = Field(0.5, ge=0.01, le=0.99)

# üìä Endpoint 1 ‚Äì analiza residuals i LOWESS
@app.post("/analyze-residuals")
def analyze_residuals(data: TriangleInput):
    max_len = max(len(row) for row in data.triangle)
    padded = [row + [np.nan] * (max_len - len(row)) for row in data.triangle]
    tri_arr = np.array(padded, dtype=float)
    tri_df = pd.DataFrame(
        tri_arr,
        index=np.arange(1, tri_arr.shape[0] + 1),
        columns=np.arange(1, tri_arr.shape[1] + 1),
    )

    alpha = data.alpha
    delta = 2 - alpha

    fitted_values, origin_periods, dev_periods, actual_vals, std_residuals = (
        [] for _ in range(5)
    )

    for j in range(tri_df.shape[1] - 1):
        x_col, y_col = tri_df.iloc[:, j], tri_df.iloc[:, j + 1]
        valid = ~(x_col.isna() | y_col.isna())

        x = x_col[valid].to_numpy(dtype=float).reshape(-1, 1)
        y = y_col[valid].to_numpy(dtype=float)
        w = 1 / np.power(x.flatten(), delta)

        lr = LinearRegression(fit_intercept=False)
        lr.fit(x, y, sample_weight=w)

        y_hat = lr.predict(x)
        residuals = y - y_hat
        rss_w = np.sum(w * residuals**2)
        n = len(y)

        if n > 1:
            sigma = np.sqrt(rss_w / (n - 1))
            S = np.sum(w * (x.flatten() ** 2))
            h = w * (x.flatten() ** 2) / S
            stud_resid = residuals * np.sqrt(w) / (sigma * np.sqrt(1 - h))
        else:
            stud_resid = np.full_like(y, np.nan)

        fitted_values.extend(y_hat)
        origin_periods.extend(x_col.index[valid])
        dev_periods.extend([j + 1] * n)
        actual_vals.extend(y)
        std_residuals.extend(stud_resid)

    residuals_raw = np.array(actual_vals) - np.array(fitted_values)

    obs_vs_fitted = pd.DataFrame({
        "origin_period": origin_periods,
        "dev_period": np.array(dev_periods),
        "cal_period": np.array(origin_periods) + np.array(dev_periods) - 1,
        "residuals": residuals_raw,
        "standard_residuals": std_residuals,
        "fitted_value": fitted_values,
    }).dropna().reset_index(drop=True)

    lowess_results = {
        "fitted_value": pd.DataFrame(lowess(obs_vs_fitted["standard_residuals"], obs_vs_fitted["fitted_value"], frac=2/3), columns=["x", "lowess"]),
        "origin_period": pd.DataFrame(lowess(obs_vs_fitted["standard_residuals"], obs_vs_fitted["origin_period"], frac=2/3), columns=["x", "lowess"]),
        "cal_period": pd.DataFrame(lowess(obs_vs_fitted["standard_residuals"], obs_vs_fitted["cal_period"], frac=2/3), columns=["x", "lowess"]),
        "dev_period": pd.DataFrame(lowess(obs_vs_fitted["standard_residuals"], obs_vs_fitted["dev_period"], frac=2/3), columns=["x", "lowess"]),
    }

    return {
        "obs_vs_fitted": obs_vs_fitted.to_dict(orient="records"),
        "lowess_results": {
            k: v.to_dict(orient="records") for k, v in lowess_results.items()
        },
    }

# üìà Endpoint 2 ‚Äì analiza zale≈ºno≈õci
@app.post("/analyze-dependence")
def analyze_dependence(data: TriangleInput):
    triangle = np.array(data.triangle, dtype=np.float64)
    ci = data.ci


    n_rows, n_cols = triangle.shape
    ata = np.full((n_rows, n_cols - 1), np.nan)

    for i in range(n_rows):
        for j in range(n_cols - 1):
            if not np.isnan(triangle[i, j]) and not np.isnan(triangle[i, j + 1]) and triangle[i, j] != 0:
                ata[i, j] = triangle[i, j + 1] / triangle[i, j]

    T_k = []
    for i in range(n_cols - 3):
        col1 = ata[:, i]
        col2 = ata[:, i + 1]
        valid = ~np.isnan(col1) & ~np.isnan(col2)
        if np.sum(valid) > 1:
            rho, _ = spearmanr(col1[valid], col2[valid])
            T_k.append(rho)

    if len(T_k) > 0:
        weights = np.arange(len(T_k), 0, -1)
        T_final = np.average(T_k, weights=weights)
        Var_T = 1 / ((n_cols - 2) * (n_cols - 3) / 2)
        Z = norm.ppf(ci + (1 - ci) / 2)
        range_ = [-Z * np.sqrt(Var_T), Z * np.sqrt(Var_T)]
    else:
        T_final = None
        Var_T = None
        range_ = [None, None]

    # üî∑ Gƒôsto≈õƒá do wykresu
    density_data = None
    if T_final is not None and Var_T is not None:
        sd = np.sqrt(Var_T)

        # Krzywa normalna (pe≈Çna)
        x_seq = np.linspace(-1, 1, 500)  # 500 punkt√≥w dla lepszej g≈Çadko≈õci
        y_seq = norm.pdf(x_seq, loc=0, scale=sd)
        # Obszar pod przedzia≈Çem ufno≈õci (zacieniowany)
        ci_x = np.arange(range_[0], range_[1], 0.01)
        ci_y = norm.pdf(ci_x, loc=0, scale=sd)

        density_data = {
            "curve": list(zip(x_seq, y_seq)),
            "ci_area": list(zip(ci_x, ci_y)),
            "T_stat": T_final,
            "T_y": norm.pdf(T_final, loc=0, scale=sd)
        }

    return {
        "T_stat": T_final,
        "Var": Var_T,
        "Range": range_,
        "ci": ci,
        "summary": {
            "results": {
                "T": T_final,
                "E[T]": 0,
                "Var[T]": Var_T
            },
            "range": {
                "Lower": range_[0],
                "Upper": range_[1]
            }
        },
        "density_plot": density_data
    }
